<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>deepinv.optim.data_fidelity &mdash; deepinverse 0.1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/logo.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=2709fde1"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/deepinv_logolarge.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.physics.html">Physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.loss.html">Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.pnp.html">PnP and RED algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.unfolded.html">Unfolded algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.sampling.html">Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.notation.html">Math Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deepinv.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">deepinverse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">deepinv.optim.data_fidelity</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for deepinv.optim.data_fidelity</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">from</span> <span class="nn">deepinv.optim.utils</span> <span class="kn">import</span> <span class="n">gradient_descent</span>


<div class="viewcode-block" id="DataFidelity">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity">[docs]</a>
<span class="k">class</span> <span class="nc">DataFidelity</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data fidelity term :math:`\datafid{x}{y}=\distance{Ax}{y}`.</span>

<span class="sd">    This is the base class for the data fidelity term :math:`\datafid{x}{y} = \distance{A(x)}{y}` where :math:`A` is a</span>
<span class="sd">    linear or nonlinear operator, :math:`x\in\xset` is a variable , :math:`y\in\yset` is the observation and</span>
<span class="sd">    :math:`\distancename` is a distance function.</span>

<span class="sd">    ::</span>

<span class="sd">        # define a loss function</span>
<span class="sd">        data_fidelity = L2()</span>

<span class="sd">        # Create a measurement operator</span>
<span class="sd">        A = torch.Tensor([[2, 0], [0, 0.5]])</span>
<span class="sd">        A_forward = lambda v: A @ v</span>
<span class="sd">        A_adjoint = lambda v: A.transpose(0, 1) @ v</span>

<span class="sd">        # Define the physics model associated to this operator</span>
<span class="sd">        physics = dinv.physics.LinearPhysics(A=A_forward, A_adjoint=A_adjoint)</span>

<span class="sd">        # Define two points</span>
<span class="sd">        x = torch.Tensor([[1], [4]]).unsqueeze(0)</span>
<span class="sd">        y = torch.Tensor([[1], [1]]).unsqueeze(0)</span>

<span class="sd">        # Compute the loss :math:`f(x) = \datafid{A(x)}{y}`</span>
<span class="sd">        f_x = data_fidelity(x, y, physics)  # print(f_x) gives tensor([1.0000])</span>

<span class="sd">        # Compute the gradient of :math:`f`</span>
<span class="sd">        grad = data_fidelity.grad(x, y, physics)  # print(grad) gives tensor([[[2.0000], [0.5000]]])</span>

<span class="sd">        # Compute the proximity operator of :math:`f`</span>
<span class="sd">        prox = data_fidelity.prox(x, y, physics, gamma=1.0)  # print(prox) gives tensor([[[0.6000], [3.6000]]])</span>


<span class="sd">    .. warning::</span>
<span class="sd">        All variables have a batch dimension as first dimension.</span>

<span class="sd">    :param callable d: data fidelity distance function :math:`\distance{u}{y}`. Outputs a tensor of size `B`, the size of the batch. Default: None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_d</span> <span class="o">=</span> <span class="n">d</span>

<div class="viewcode-block" id="DataFidelity.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the data fidelity distance :math:`\distance{u}{y}`.</span>

<span class="sd">        :param torch.tensor u: Variable :math:`u` at which the distance function is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :return: (torch.tensor) data fidelity :math:`\distance{u}{y}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.grad_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.grad_d">[docs]</a>
    <span class="k">def</span> <span class="nf">grad_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gradient :math:`\nabla_u\distance{u}{y}`, computed in :math:`u`. Note that this is the gradient of</span>
<span class="sd">        :math:`\distancename` and not :math:`\datafidname`. By default, the gradient is computed using automatic differentiation.</span>

<span class="sd">        :param torch.tensor u: Variable :math:`u` at which the gradient is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y` of the same dimension as :math:`u`.</span>
<span class="sd">        :return: (torch.tensor) gradient of :math:`d` in :math:`u`, i.e. :math:`\nabla_u\distance{u}{y}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">u</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">only_inputs</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">grad</span></div>


<div class="viewcode-block" id="DataFidelity.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">u</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">stepsize_inter</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">max_iter_inter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">tol_inter</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the proximity operator :math:`\operatorname{prox}_{\gamma\distance{\cdot}{y}}(u)`, computed in :math:`u`. Note</span>
<span class="sd">        that this is the proximity operator of :math:`\distancename` and not :math:`\datafidname`. By default, the proximity operator is computed using internal gradient descent.</span>

<span class="sd">        :param torch.tensor u: Variable :math:`u` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y` of the same dimension as :math:`u`.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :param float stepsize_inter: stepsize used for internal gradient descent</span>
<span class="sd">        :param int max_iter_inter: maximal number of iterations for internal gradient descent.</span>
<span class="sd">        :param float tol_inter: internal gradient descent has converged when the L2 distance between two consecutive iterates is smaller than tol_inter.</span>
<span class="sd">        :return: (torch.tensor) proximity operator :math:`\operatorname{prox}_{\gamma\distance{\cdot}{y}}(u)`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">z</span><span class="p">:</span> <span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_d</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gradient_descent</span><span class="p">(</span>
            <span class="n">grad</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="n">stepsize_inter</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter_inter</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol_inter</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.forward">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the data fidelity term :math:`\datafid{x}{y} = \distance{Ax}{y}`.</span>

<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the data fidelity is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :return: (torch.tensor) data fidelity :math:`\datafid{x}{y}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">(</span><span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.grad">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.grad">[docs]</a>
    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the gradient of the data fidelity term :math:`\datafidname` at :math:`x`.</span>

<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the gradient is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :return: (torch.tensor) gradient :math:`\nabla_x\datafid{x}{y}`, computed in :math:`x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">physics</span><span class="o">.</span><span class="n">A_adjoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad_d</span><span class="p">(</span><span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span></div>


<div class="viewcode-block" id="DataFidelity.prox">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.prox">[docs]</a>
    <span class="k">def</span> <span class="nf">prox</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">physics</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">stepsize_inter</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">max_iter_inter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">tol_inter</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the proximity operator of :math:`\datafidname` at :math:`x`.</span>

<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :param float stepsize_inter: stepsize used for internal gradient descent</span>
<span class="sd">        :param int max_iter_inter: maximal number of iterations for internal gradient descent.</span>
<span class="sd">        :param float tol_inter: internal gradient descent has converged when the L2 distance between two consecutive iterates is smaller than tol_inter.</span>
<span class="sd">        :return: (torch.tensor) proximity operator :math:`\operatorname{prox}_{\gamma \datafidname}(x)`, computed in :math:`x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">z</span><span class="p">:</span> <span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gradient_descent</span><span class="p">(</span>
            <span class="n">grad</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="n">stepsize_inter</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter_inter</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol_inter</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.prox_conjugate">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.prox_conjugate">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_conjugate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the proximity operator of the convex conjugate :math:`(\lambda \datafidname)^*` at :math:`x`,</span>
<span class="sd">        using the Moreau formula.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            This function is only valid for convex :math:`\datafidname`.</span>

<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :param float lamb: math:`\lambda` parameter in front of :math:`f`</span>
<span class="sd">        :return: (torch.tensor) proximity operator :math:`\operatorname{prox}_{\gamma (\lambda \datafidname)^*}(x)`,</span>
<span class="sd">            computed in :math:`x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox</span><span class="p">(</span>
            <span class="n">x</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="n">lamb</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DataFidelity.prox_d_conjugate">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity.prox_d_conjugate">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d_conjugate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">lamb</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the proximity operator of the convex conjugate :math:`(\lambda \distancename)^*` at :math:`u`,</span>
<span class="sd">        using the Moreau formula.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            This function is only valid for convex :math:`\distancename`.</span>

<span class="sd">        :param torch.tensor u: Variable :math:`u` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :param float lamb: math:`\lambda` parameter in front of :math:`\distancename`</span>
<span class="sd">        :return: (torch.tensor) proximity operator :math:`\operatorname{prox}_{\gamma (\lambda \distancename)^*}(x)`,</span>
<span class="sd">            computed in :math:`x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">u</span> <span class="o">-</span> <span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_d</span><span class="p">(</span><span class="n">u</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lamb</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="L2">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2">[docs]</a>
<span class="k">class</span> <span class="nc">L2</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of :math:`\distancename` as the normalized :math:`\ell_2` norm</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = \frac{1}{2\sigma^2}\|Ax-y\|^2</span>

<span class="sd">    It can be used to define a log-likelihood function associated with additive Gaussian noise</span>
<span class="sd">    by setting an appropriate noise level :math:`\sigma`.</span>

<span class="sd">    :param float sigma: Standard deviation of the noise to be used as a normalisation factor.</span>


<span class="sd">    ::</span>

<span class="sd">        # define a loss function</span>
<span class="sd">        loss = L2()</span>

<span class="sd">        # create a measurement operator</span>
<span class="sd">        A = torch.Tensor([[2, 0], [0, 0.5]])</span>
<span class="sd">        A_forward = lambda v:A@v</span>
<span class="sd">        A_adjoint = lambda v: A.transpose(0,1)@v</span>

<span class="sd">        # Define the physics model associated to this operator</span>
<span class="sd">        physics = dinv.physics.LinearPhysics(A=A_forward, A_adjoint=A_adjoint)</span>

<span class="sd">        # Define two points</span>
<span class="sd">        x = torch.Tensor([1, 4])</span>
<span class="sd">        y = torch.Tensor([1, 1])</span>

<span class="sd">        # Compute the loss f(Ax, y)</span>
<span class="sd">        f = loss(x, y, physics)  # print f gives 1.0</span>

<span class="sd">        # Compute the gradient of f</span>
<span class="sd">        grad_dA = data_fidelity.grad(x, y, physics)  # print grad_d gives [2.0000, 0.5000]</span>

<span class="sd">        # Compute the proximity operator of f</span>
<span class="sd">        prox_dA = data_fidelity.prox(x, y, physics, gamma=1.0)  # print prox_dA gives [0.6000, 3.6000]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<div class="viewcode-block" id="L2.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the data fidelity distance :math:`\datafid{u}{y}`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \datafid{u}{y} = \frac{1}{2\sigma^2}\|u-y\|^2</span>


<span class="sd">        :param torch.tensor u: Variable :math:`u` at which the data fidelity is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :return: (torch.tensor) data fidelity :math:`\datafid{u}{y}` of size `B` with `B` the size of the batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">u</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">d</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">d</span></div>


<div class="viewcode-block" id="L2.grad_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2.grad_d">[docs]</a>
    <span class="k">def</span> <span class="nf">grad_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gradient of :math:`\distancename`, that is  :math:`\nabla_{u}\distance{u}{y}`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \nabla_{u}\distance{u}{y} = \frac{1}{\sigma^2}(u-y)</span>


<span class="sd">        :param torch.tensor u: Variable :math:`u` at which the gradient is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :return: (torch.tensor) gradient of the distance function :math:`\nabla_{u}\distance{u}{y}`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span></div>


<div class="viewcode-block" id="L2.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of :math:`\gamma \distance{x}{y} = \frac{\gamma}{2\sigma^2}\|x-y\|^2`.</span>

<span class="sd">        Computes :math:`\operatorname{prox}_{\gamma \distancename}`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">           \operatorname{prox}_{\gamma \distancename} = \underset{u}{\text{argmin}} \frac{\gamma}{2\sigma^2}\|u-y\|_2^2+\frac{1}{2}\|u-x\|_2^2</span>


<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :param float gamma: thresholding parameter.</span>
<span class="sd">        :return: (torch.tensor) proximity operator :math:`\operatorname{prox}_{\gamma \distancename}(x)`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">gamma_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">*</span> <span class="n">gamma</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">gamma_</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">gamma_</span><span class="p">)</span></div>


<div class="viewcode-block" id="L2.prox">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L2.html#deepinv.optim.L2.prox">[docs]</a>
    <span class="k">def</span> <span class="nf">prox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of :math:`\gamma \datafid{Ax}{y} = \frac{\gamma}{2\sigma^2}\|Ax-y\|^2`.</span>

<span class="sd">        Computes :math:`\operatorname{prox}_{\gamma \datafidname}`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">           \operatorname{prox}_{\gamma \datafidname} = \underset{u}{\text{argmin}} \frac{\gamma}{2\sigma^2}\|Au-y\|_2^2+\frac{1}{2}\|u-x\|_2^2</span>


<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :param float gamma: stepsize of the proximity operator.</span>
<span class="sd">        :return: (torch.tensor) proximity operator :math:`\operatorname{prox}_{\gamma \datafidname}(x)`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">physics</span><span class="o">.</span><span class="n">prox_l2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">*</span> <span class="n">gamma</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="IndicatorL2">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.IndicatorL2.html#deepinv.optim.IndicatorL2">[docs]</a>
<span class="k">class</span> <span class="nc">IndicatorL2</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Indicator of :math:`\ell_2` ball with radius :math:`r`.</span>

<span class="sd">    The indicator function of the $\ell_2$ ball with radius :math:`r`, denoted as \iota_{\mathcal{B}_2(y,r)(u)},</span>
<span class="sd">    is defined as</span>

<span class="sd">    .. math::</span>

<span class="sd">          \iota_{\mathcal{B}_2(y,r)}(u)= \left.</span>
<span class="sd">              \begin{cases}</span>
<span class="sd">                0, &amp; \text{if } \|u-y\|_2\leq r \\</span>
<span class="sd">                +\infty &amp; \text{else.}</span>
<span class="sd">              \end{cases}</span>
<span class="sd">              \right.</span>


<span class="sd">    :param float radius: radius of the ball. Default: None.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">radius</span> <span class="o">=</span> <span class="n">radius</span>

<div class="viewcode-block" id="IndicatorL2.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.IndicatorL2.html#deepinv.optim.IndicatorL2.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the batched indicator of :math:`\ell_2` ball with radius `radius`, i.e. :math:`\iota_{\mathcal{B}(y,r)}(u)`.</span>

<span class="sd">        :param torch.tensor u: Variable :math:`u` at which the indicator is computed. :math:`u` is assumed to be of shape (B, ...) where B is the batch size.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y` of the same dimension as :math:`u`.</span>
<span class="sd">        :param float radius: radius of the :math:`\ell_2` ball. If `radius` is None, the radius of the ball is set to `self.radius`. Default: None.</span>
<span class="sd">        :return: (torch.tensor) indicator of :math:`\ell_2` ball with radius `radius`. If the point is inside the ball, the output is 0, else it is 1e16.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">u</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">radius</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radius</span> <span class="k">if</span> <span class="n">radius</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">radius</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&gt;</span> <span class="n">radius</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e16</span>
        <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="IndicatorL2.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.IndicatorL2.html#deepinv.optim.IndicatorL2.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of the indicator of :math:`\ell_2` ball with radius `radius`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \operatorname{prox}_{\iota_{\mathcal{B}_2(y,r)}}(x) = \operatorname{proj}_{\mathcal{B}_2(y, r)}(x)</span>


<span class="sd">        where :math:`\operatorname{proj}_{C}(x)` denotes the projection on the closed convex set :math:`C`.</span>


<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y` of the same dimension as :math:`x`.</span>
<span class="sd">        :param float gamma: step-size. Note that this parameter is not used in this function.</span>
<span class="sd">        :param float radius: radius of the :math:`\ell_2` ball.</span>
<span class="sd">        :return: (torch.tensor) projection on the :math:`\ell_2` ball of radius `radius` and centered in `y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">radius</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radius</span> <span class="k">if</span> <span class="n">radius</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">radius</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span> <span class="o">+</span> <span class="n">diff</span> <span class="o">*</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">radius</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">dist</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">dist</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="IndicatorL2.prox">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.IndicatorL2.html#deepinv.optim.IndicatorL2.prox">[docs]</a>
    <span class="k">def</span> <span class="nf">prox</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">physics</span><span class="p">,</span>
        <span class="n">radius</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">stepsize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">crit_conv</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of the indicator of :math:`\ell_2` ball with radius `radius`, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \operatorname{prox}_{\gamma \iota_{\mathcal{B}_2(y, r)}(A\cdot)}(x) = \underset{u}{\text{argmin}} \,\, \iota_{\mathcal{B}_2(y, r)}(Au)+\frac{1}{2}\|u-x\|_2^2</span>

<span class="sd">        Since no closed form is available for general measurement operators, we use a dual forward-backward algorithm,</span>
<span class="sd">        as suggested in `Proximal Splitting Methods in Signal Processing &lt;https://arxiv.org/pdf/0912.3522.pdf&gt;`_.</span>

<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y` of the same dimension as :math:`A(x)`.</span>
<span class="sd">        :param torch.tensor radius: radius of the :math:`\ell_2` ball.</span>
<span class="sd">        :param float stepsize: step-size of the dual-forward-backward algorithm.</span>
<span class="sd">        :param float crit_conv: convergence criterion of the dual-forward-backward algorithm.</span>
<span class="sd">        :param int max_iter: maximum number of iterations of the dual-forward-backward algorithm.</span>
<span class="sd">        :param float gamma: factor in front of the indicator function. Notice that this does not affect the proximity</span>
<span class="sd">                            operator since the indicator is scale invariant. Default: None.</span>
<span class="sd">        :return: (torch.tensor) projection on the :math:`\ell_2` ball of radius `radius` and centered in `y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">radius</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radius</span> <span class="k">if</span> <span class="n">radius</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">radius</span>

        <span class="k">if</span> <span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="ow">and</span> <span class="p">(</span><span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>  <span class="c1"># Identity case</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="n">radius</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">norm_AtA</span> <span class="o">=</span> <span class="n">physics</span><span class="o">.</span><span class="n">compute_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">stepsize</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">norm_AtA</span> <span class="k">if</span> <span class="n">stepsize</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">stepsize</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
                <span class="n">u_prev</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

                <span class="n">t</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">physics</span><span class="o">.</span><span class="n">A_adjoint</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
                <span class="n">u_</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
                <span class="n">u</span> <span class="o">=</span> <span class="n">u_</span> <span class="o">-</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_d</span><span class="p">(</span>
                    <span class="n">u_</span> <span class="o">/</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="n">radius</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span>
                <span class="p">)</span>
                <span class="n">rel_crit</span> <span class="o">=</span> <span class="p">((</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_prev</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">rel_crit</span> <span class="o">&lt;</span> <span class="n">crit_conv</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="k">return</span> <span class="n">t</span></div>
</div>



<div class="viewcode-block" id="PoissonLikelihood">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.PoissonLikelihood.html#deepinv.optim.PoissonLikelihood">[docs]</a>
<span class="k">class</span> <span class="nc">PoissonLikelihood</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Poisson negative log-likelihood.</span>

<span class="sd">    .. math::</span>

<span class="sd">        \datafid{z}{y} =  -y^{\top} \log(z+\beta)+1^{\top}z</span>

<span class="sd">    where :math:`y` are the measurements, :math:`z` is the estimated (positive) density and :math:`\beta\geq 0` is</span>
<span class="sd">    an optional background level.</span>

<span class="sd">    .. note::</span>

<span class="sd">        The function is not Lipschitz smooth w.r.t. :math:`z` in the absence of background (:math:`\beta=0`).</span>

<span class="sd">    :param float bkg: background level :math:`\beta`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">bkg</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bkg</span> <span class="o">=</span> <span class="n">bkg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>

<div class="viewcode-block" id="PoissonLikelihood.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.PoissonLikelihood.html#deepinv.optim.PoissonLikelihood.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span>
        <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">y</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bkg</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">*</span> <span class="n">x</span>
        <span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></div>


<div class="viewcode-block" id="PoissonLikelihood.grad_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.PoissonLikelihood.html#deepinv.optim.PoissonLikelihood.grad_d">[docs]</a>
    <span class="k">def</span> <span class="nf">grad_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span>
        <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bkg</span><span class="p">))</span></div>


<div class="viewcode-block" id="PoissonLikelihood.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.PoissonLikelihood.html#deepinv.optim.PoissonLikelihood.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">x</span>
            <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">)</span>
            <span class="o">*</span> <span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">y</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span> <span class="o">/</span> <span class="mi">2</span></div>
</div>



<div class="viewcode-block" id="L1">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1">[docs]</a>
<span class="k">class</span> <span class="nc">L1</span><span class="p">(</span><span class="n">DataFidelity</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :math:`\ell_1` data fidelity term.</span>

<span class="sd">    In this case, the data fidelity term is defined as</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = \|Ax-y\|_1.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="L1.d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1.d">[docs]</a>
    <span class="k">def</span> <span class="nf">d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="L1.grad_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1.grad_d">[docs]</a>
    <span class="k">def</span> <span class="nf">grad_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gradient of the gradient of the :math:`\ell_1` norm, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \partial \datafid(x) = \operatorname{sign}(x-y)</span>


<span class="sd">        .. note::</span>

<span class="sd">            The gradient is not defined at :math:`x=y`.</span>


<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the gradient is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y` of the same dimension as :math:`x`.</span>
<span class="sd">        :return: (torch.tensor) gradient of the :math:`\ell_1` norm at `x`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span></div>


<div class="viewcode-block" id="L1.prox_d">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1.prox_d">[docs]</a>
    <span class="k">def</span> <span class="nf">prox_d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of the :math:`\ell_1` norm, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \operatorname{prox}_{\gamma \ell_1}(x) = \underset{z}{\text{argmin}} \,\, \gamma \|z-y\|_1+\frac{1}{2}\|z-x\|_2^2</span>


<span class="sd">        also known as the soft-thresholding operator.</span>

<span class="sd">        :param torch.tensor u: Variable :math:`u` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y` of the same dimension as :math:`x`.</span>
<span class="sd">        :param float gamma: stepsize (or soft-thresholding parameter).</span>
<span class="sd">        :return: (torch.tensor) soft-thresholding of `u` with parameter `gamma`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">u</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">aux</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
            <span class="n">d</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">-</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">aux</span> <span class="o">+</span> <span class="n">y</span></div>


<div class="viewcode-block" id="L1.prox">
<a class="viewcode-back" href="../../../stubs/deepinv.optim.L1.html#deepinv.optim.L1.prox">[docs]</a>
    <span class="k">def</span> <span class="nf">prox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">stepsize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">crit_conv</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Proximal operator of the :math:`\ell_1` norm composed with A, i.e.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \operatorname{prox}_{\gamma \ell_1}(x) = \underset{u}{\text{argmin}} \,\, \gamma \|Au-y\|_1+\frac{1}{2}\|u-x\|_2^2.</span>



<span class="sd">        Since no closed form is available for general measurement operators, we use a dual forward-backward algorithm.</span>


<span class="sd">        :param torch.tensor x: Variable :math:`x` at which the proximity operator is computed.</span>
<span class="sd">        :param torch.tensor y: Data :math:`y` of the same dimension as :math:`A(x)`.</span>
<span class="sd">        :param deepinv.physics.Physics physics: physics model.</span>
<span class="sd">        :param float stepsize: step-size of the dual-forward-backward algorithm.</span>
<span class="sd">        :param float crit_conv: convergence criterion of the dual-forward-backward algorithm.</span>
<span class="sd">        :param int max_iter: maximum number of iterations of the dual-forward-backward algorithm.</span>
<span class="sd">        :return: (torch.tensor) projection on the :math:`\ell_2` ball of radius `radius` and centered in `y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">norm_AtA</span> <span class="o">=</span> <span class="n">physics</span><span class="o">.</span><span class="n">compute_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">stepsize</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">norm_AtA</span> <span class="k">if</span> <span class="n">stepsize</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">stepsize</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="n">u_prev</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

            <span class="n">t</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">physics</span><span class="o">.</span><span class="n">A_adjoint</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
            <span class="n">u_</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="n">physics</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">u_</span> <span class="o">-</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_d</span><span class="p">(</span><span class="n">u_</span> <span class="o">/</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">/</span> <span class="n">stepsize</span><span class="p">)</span>
            <span class="n">rel_crit</span> <span class="o">=</span> <span class="p">((</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_prev</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">rel_crit</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">rel_crit</span> <span class="o">&lt;</span> <span class="n">crit_conv</span> <span class="ow">and</span> <span class="n">it</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">return</span> <span class="n">t</span></div>
</div>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">deepinv</span> <span class="k">as</span> <span class="nn">dinv</span>

    <span class="c1"># define a loss function</span>
    <span class="n">data_fidelity</span> <span class="o">=</span> <span class="n">L2</span><span class="p">()</span>

    <span class="c1"># create a measurement operator dxd</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
    <span class="n">A_forward</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="n">A_adjoint</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">v</span><span class="p">)</span>

    <span class="c1"># Define the physics model associated to this operator</span>
    <span class="n">physics</span> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">physics</span><span class="o">.</span><span class="n">LinearPhysics</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">A_forward</span><span class="p">,</span> <span class="n">A_adjoint</span><span class="o">=</span><span class="n">A_adjoint</span><span class="p">)</span>

    <span class="c1"># Define two points of size Bxd</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Compute the loss :math:`f(x) = \datafid{A(x)}{y}`</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">data_fidelity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">)</span>  <span class="c1"># print f gives 1.0</span>
    <span class="c1"># Compute the gradient of :math:`f`</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">data_fidelity</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">)</span>  <span class="c1"># print grad_f gives [2.0000, 0.5000]</span>

    <span class="c1"># Compute the proximity operator of :math:`f`</span>
    <span class="n">prox</span> <span class="o">=</span> <span class="n">data_fidelity</span><span class="o">.</span><span class="n">prox</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span>
    <span class="p">)</span>  <span class="c1"># print prox_fA gives [0.6000, 3.6000]</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, DeepInv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEKFKYSGR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NSEKFKYSGR', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>OptimIterator &mdash; deepinverse 0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/logo.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=2709fde1"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script>window.MathJax = {"tex": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}, "macros": {"forw": ["{A\\left({#1}\\right)}", 1], "noise": ["{N\\left({#1}\\right)}", 1], "inverse": ["{R\\left({#1}\\right)}", 1], "inversef": ["{R\\left({#1},{#2}\\right)}", 2], "reg": ["{g\\left({#1}\\right)}", 1], "regname": "g", "sensor": ["{\\eta\\left({#1}\\right)}", 1], "datafid": ["{f\\left({#1},{#2}\\right)}", 2], "datafidname": "f", "distance": ["{d\\left({#1},{#2}\\right)}", 2], "distancename": "d", "denoiser": ["{\\operatorname{D}_{{#2}}\\left({#1}\\right)}", 2], "denoisername": "\\operatorname{D}", "xset": "\\mathcal{X}", "yset": "\\mathcal{Y}", "group": "\\mathcal{G}", "metric": ["{d\\left({#1},{#2}\\right)}", 2], "loss": ["{\\mathcal\\left({#1}\\right)}", 1]}}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="fStep" href="deepinv.optim.optim_iterators.optim_iterator.fStep.html" />
    <link rel="prev" title="FixedPoint" href="deepinv.optim.FixedPoint.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../index.html">
            
              <img src="../_static/deepinv_logolarge.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../deepinv.physics.html">Physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.loss.html">Loss</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../deepinv.optim.html">Optim</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="deepinv.optim.optim_builder.html">optim_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepinv.optim.BaseOptim.html">BaseOptim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.optim.html#data-fidelity">Data Fidelity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.optim.html#priors">Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.optim.html#parameters">Parameters</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../deepinv.optim.html#iterators">Iterators</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="deepinv.optim.FixedPoint.html">FixedPoint</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../deepinv.optim.html#generic-optimizers">Generic optimizers</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">OptimIterator</a></li>
<li class="toctree-l4"><a class="reference internal" href="deepinv.optim.optim_iterators.optim_iterator.fStep.html">fStep</a></li>
<li class="toctree-l4"><a class="reference internal" href="deepinv.optim.optim_iterators.optim_iterator.gStep.html">gStep</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../deepinv.optim.html#admm">ADMM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deepinv.optim.html#douglas-rachford-splitting">Douglas-Rachford Splitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deepinv.optim.html#gradient-descent">Gradient Descent</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deepinv.optim.html#proximal-gradient-descent">Proximal Gradient Descent</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deepinv.optim.html#half-quadratic-splitting">Half-Quadratic Splitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../deepinv.optim.html#chambolle-pock-primal-dual-splitting">Chambolle-Pock Primal-Dual Splitting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.pnp.html">PnP and RED algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.unfolded.html">Unfolded algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.sampling.html">Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.notation.html">Math Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">deepinverse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../deepinv.optim.html">Optim</a></li>
      <li class="breadcrumb-item active">OptimIterator</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/stubs/deepinv.optim.optim_iterators.OptimIterator.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="optimiterator">
<h1>OptimIterator<a class="headerlink" href="#optimiterator" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="deepinv.optim.optim_iterators.OptimIterator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepinv.optim.optim_iterators.</span></span><span class="sig-name descname"><span class="pre">OptimIterator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">g_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">has_cost</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/optim_iterators/optim_iterator.html#OptimIterator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.optim_iterators.OptimIterator" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Base class for all <code class="xref py py-meth docutils literal notranslate"><span class="pre">Optim()</span></code> iterators.</p>
<p>An optim iterator is an object that implements a fixed point iteration for minimizing the sum of two functions
<span class="math notranslate nohighlight">\(F = \lambda*f + g\)</span> where <span class="math notranslate nohighlight">\(f\)</span> is a data-fidelity term  that will be modeled by an instance of physics
and g is a regularizer. The fixed point iteration takes the form</p>
<div class="math notranslate nohighlight">
\[\qquad (x_{k+1}, z_{k+1}) = \operatorname{FixedPoint}(x_k, z_k, f, g, A, y, ...)\]</div>
<p>where <span class="math notranslate nohighlight">\(x\)</span> is a “primal” variable converging to the solution of the minimization problem, and
<span class="math notranslate nohighlight">\(z\)</span> is a “dual” variable.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By an abuse of terminology, we call “primal” and “dual” variables the variables that are updated
at each step and which may correspond to the actual primal and dual variables from
(for instance in the case of the PD algorithm), but not necessarily (for instance in the case of the
PGD algorithm).</p>
</div>
<p>The implementation of the fixed point algorithm in <code class="xref py py-meth docutils literal notranslate"><span class="pre">deepinv.optim()</span></code>  is split in two steps, alternating between
a step on f and a step on g, that is for <span class="math notranslate nohighlight">\(k=1,2,...\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}z_{k+1} = \operatorname{step}_f(x_k, z_k, y, A, ...)\\
x_{k+1} = \operatorname{step}_g(x_k, z_k, y, A, ...)\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\operatorname{step}_f\)</span> and <span class="math notranslate nohighlight">\(\operatorname{step}_g\)</span> are the steps on f and g respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>g_first</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – If True, the algorithm starts with a step on g and finishes with a step on f.</p></li>
<li><p><strong>F_fn</strong> – function that returns the function F to be minimized at each iteration. Default: None.</p></li>
<li><p><strong>has_cost</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) – If True, the function F is computed at each iteration. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.optim_iterators.OptimIterator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cur_data_fidelity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cur_prior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cur_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">physics</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/optim_iterators/optim_iterator.html#OptimIterator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.optim_iterators.OptimIterator.forward" title="Link to this definition"></a></dt>
<dd><p>General form of a single iteration of splitting algorithms for minimizing <span class="math notranslate nohighlight">\(F = \lambda f + g\)</span>, alternating
between a step on <span class="math notranslate nohighlight">\(f\)</span> and a step on <span class="math notranslate nohighlight">\(g\)</span>.
The primal and dual variables as well as the estimated cost at the current iterate are stored in a dictionary
$X$ of the form <cite>{‘est’: (x,z), ‘cost’: F}</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="(in Python v3.4)"><em>dict</em></a>) – Dictionary containing the current iterate and the estimated cost.</p></li>
<li><p><strong>cur_data_fidelity</strong> (<a class="reference internal" href="deepinv.optim.DataFidelity.html#deepinv.optim.DataFidelity" title="deepinv.optim.DataFidelity"><em>deepinv.optim.DataFidelity</em></a>) – Instance of the DataFidelity class defining the current data_fidelity.</p></li>
<li><p><strong>cur_prior</strong> (<em>deepinv.optim.prior</em>) – Instance of the Prior class defining the current prior.</p></li>
<li><p><strong>cur_params</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="(in Python v3.4)"><em>dict</em></a>) – Dictionary containing the current parameters of the algorithm.</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – Input data.</p></li>
<li><p><strong>physics</strong> (<em>deepinv.physics</em>) – Instance of the physics modeling the observation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary <cite>{“est”: (x, z), “cost”: F}</cite> containing the updated current iterate and the estimated current cost.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.optim_iterators.OptimIterator.relaxation_step">
<span class="sig-name descname"><span class="pre">relaxation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/optim_iterators/optim_iterator.html#OptimIterator.relaxation_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.optim_iterators.OptimIterator.relaxation_step" title="Link to this definition"></a></dt>
<dd><p>Performs a relaxation step of the form <span class="math notranslate nohighlight">\(\beta u + (1-\beta) v\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<a class="reference external" href="https://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – First tensor.</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/2.0/tensors.html#torch.Tensor" title="(in PyTorch v2.0)"><em>torch.Tensor</em></a>) – Second tensor.</p></li>
<li><p><strong>beta</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – Relaxation parameter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Relaxed tensor.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-optimiterator">
<span id="sphx-glr-backref-deepinv-optim-optim-iterators-optimiterator"></span><h2>Examples using <code class="docutils literal notranslate"><span class="pre">OptimIterator</span></code>:<a class="headerlink" href="#examples-using-optimiterator" title="Link to this heading"></a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to define your own optimization algorithm. For example, here, we impleme..."><img alt="" src="../_images/sphx_glr_demo_PnP_custom_optim_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_PnP_custom_optim.html#sphx-glr-auto-examples-plug-and-play-demo-pnp-custom-optim-py"><span class="std std-ref">PnP with custom optimization algorithm (Condat-Vu Primal-Dual)</span></a></p>
  <div class="sphx-glr-thumbnail-title">PnP with custom optimization algorithm (Condat-Vu Primal-Dual)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Adler, Jonas, and Ozan Öktem.  &quot;Learned primal-dual reconstruction.&quot;  IEEE transactions on medi..."><img alt="" src="../_images/sphx_glr_demo_learned_primal_dual_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_learned_primal_dual.html#sphx-glr-auto-examples-unfolded-demo-learned-primal-dual-py"><span class="std std-ref">Learned Primal-Dual algorithm for CT scan.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Learned Primal-Dual algorithm for CT scan.</div>
</div></div></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="deepinv.optim.FixedPoint.html" class="btn btn-neutral float-left" title="FixedPoint" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="deepinv.optim.optim_iterators.optim_iterator.fStep.html" class="btn btn-neutral float-right" title="fStep" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, DeepInv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEKFKYSGR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NSEKFKYSGR', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>
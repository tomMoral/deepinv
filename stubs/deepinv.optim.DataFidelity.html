<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DataFidelity &mdash; deepinverse 0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/logo.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=2709fde1"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script>window.MathJax = {"tex": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}, "macros": {"forw": ["{A\\left({#1}\\right)}", 1], "noise": ["{N\\left({#1}\\right)}", 1], "inverse": ["{R\\left({#1}\\right)}", 1], "inversef": ["{R\\left({#1},{#2}\\right)}", 2], "reg": ["{g\\left({#1}\\right)}", 1], "regname": "g", "sensor": ["{\\eta\\left({#1}\\right)}", 1], "datafid": ["{f\\left({#1},{#2}\\right)}", 2], "datafidname": "f", "distance": ["{d\\left({#1},{#2}\\right)}", 2], "distancename": "d", "denoiser": ["{\\operatorname{D}_{{#2}}\\left({#1}\\right)}", 2], "denoisername": "\\operatorname{D}", "xset": "\\mathcal{X}", "yset": "\\mathcal{Y}", "group": "\\mathcal{G}", "metric": ["{d\\left({#1},{#2}\\right)}", 2], "loss": ["{\\mathcal\\left({#1}\\right)}", 1]}}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="L1" href="deepinv.optim.L1.html" />
    <link rel="prev" title="BaseOptim" href="deepinv.optim.BaseOptim.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../index.html">
            
              <img src="../_static/deepinv_logolarge.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../deepinv.physics.html">Physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.loss.html">Loss</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../deepinv.optim.html">Optim</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="deepinv.optim.optim_builder.html">optim_builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepinv.optim.BaseOptim.html">BaseOptim</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../deepinv.optim.html#data-fidelity">Data Fidelity</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">DataFidelity</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#deepinv.optim.DataFidelity"><code class="docutils literal notranslate"><span class="pre">DataFidelity</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-datafidelity">Examples using <code class="docutils literal notranslate"><span class="pre">DataFidelity</span></code>:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="deepinv.optim.L1.html">L1</a></li>
<li class="toctree-l3"><a class="reference internal" href="deepinv.optim.L2.html">L2</a></li>
<li class="toctree-l3"><a class="reference internal" href="deepinv.optim.IndicatorL2.html">IndicatorL2</a></li>
<li class="toctree-l3"><a class="reference internal" href="deepinv.optim.PoissonLikelihood.html">PoissonLikelihood</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.optim.html#priors">Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.optim.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deepinv.optim.html#iterators">Iterators</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.pnp.html">PnP and RED algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.unfolded.html">Unfolded algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.sampling.html">Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.notation.html">Math Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepinv.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">deepinverse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../deepinv.optim.html">Optim</a></li>
      <li class="breadcrumb-item active">DataFidelity</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/stubs/deepinv.optim.DataFidelity.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="datafidelity">
<h1>DataFidelity<a class="headerlink" href="#datafidelity" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="deepinv.optim.DataFidelity">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepinv.optim.</span></span><span class="sig-name descname"><span class="pre">DataFidelity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/data_fidelity.html#DataFidelity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.DataFidelity" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>Data fidelity term <span class="math notranslate nohighlight">\(\datafid{x}{y}=\distance{Ax}{y}\)</span>.</p>
<p>This is the base class for the data fidelity term <span class="math notranslate nohighlight">\(\datafid{x}{y} = \distance{A(x)}{y}\)</span> where <span class="math notranslate nohighlight">\(A\)</span> is a
linear or nonlinear operator, <span class="math notranslate nohighlight">\(x\in\xset\)</span> is a variable , <span class="math notranslate nohighlight">\(y\in\yset\)</span> is the observation and
<span class="math notranslate nohighlight">\(\distancename\)</span> is a distance function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># define a loss function</span>
<span class="n">data_fidelity</span> <span class="o">=</span> <span class="n">L2</span><span class="p">()</span>

<span class="c1"># Create a measurement operator</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
<span class="n">A_forward</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">A</span> <span class="o">@</span> <span class="n">v</span>
<span class="n">A_adjoint</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">A</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">@</span> <span class="n">v</span>

<span class="c1"># Define the physics model associated to this operator</span>
<span class="n">physics</span> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">physics</span><span class="o">.</span><span class="n">LinearPhysics</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">A_forward</span><span class="p">,</span> <span class="n">A_adjoint</span><span class="o">=</span><span class="n">A_adjoint</span><span class="p">)</span>

<span class="c1"># Define two points</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">]])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Compute the loss :math:`f(x) = \datafid{A(x)}{y}`</span>
<span class="n">f_x</span> <span class="o">=</span> <span class="n">data_fidelity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">)</span>  <span class="c1"># print(f_x) gives tensor([1.0000])</span>

<span class="c1"># Compute the gradient of :math:`f`</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">data_fidelity</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">)</span>  <span class="c1"># print(grad) gives tensor([[[2.0000], [0.5000]]])</span>

<span class="c1"># Compute the proximity operator of :math:`f`</span>
<span class="n">prox</span> <span class="o">=</span> <span class="n">data_fidelity</span><span class="o">.</span><span class="n">prox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">physics</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>  <span class="c1"># print(prox) gives tensor([[[0.6000], [3.6000]]])</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>All variables have a batch dimension as first dimension.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>d</strong> (<em>callable</em>) – data fidelity distance function <span class="math notranslate nohighlight">\(\distance{u}{y}\)</span>. Outputs a tensor of size <cite>B</cite>, the size of the batch. Default: None.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.DataFidelity.d">
<span class="sig-name descname"><span class="pre">d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/data_fidelity.html#DataFidelity.d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.DataFidelity.d" title="Link to this definition"></a></dt>
<dd><p>Computes the data fidelity distance <span class="math notranslate nohighlight">\(\distance{u}{y}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>torch.tensor</em>) – Variable <span class="math notranslate nohighlight">\(u\)</span> at which the distance function is computed.</p></li>
<li><p><strong>y</strong> (<em>torch.tensor</em>) – Data <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.tensor) data fidelity <span class="math notranslate nohighlight">\(\distance{u}{y}\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.DataFidelity.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">physics</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/data_fidelity.html#DataFidelity.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.DataFidelity.forward" title="Link to this definition"></a></dt>
<dd><p>Computes the data fidelity term <span class="math notranslate nohighlight">\(\datafid{x}{y} = \distance{Ax}{y}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.tensor</em>) – Variable <span class="math notranslate nohighlight">\(x\)</span> at which the data fidelity is computed.</p></li>
<li><p><strong>y</strong> (<em>torch.tensor</em>) – Data <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
<li><p><strong>physics</strong> (<a class="reference internal" href="deepinv.physics.Physics.html#deepinv.physics.Physics" title="deepinv.physics.Physics"><em>deepinv.physics.Physics</em></a>) – physics model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.tensor) data fidelity <span class="math notranslate nohighlight">\(\datafid{x}{y}\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.DataFidelity.grad">
<span class="sig-name descname"><span class="pre">grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">physics</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/data_fidelity.html#DataFidelity.grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.DataFidelity.grad" title="Link to this definition"></a></dt>
<dd><p>Calculates the gradient of the data fidelity term <span class="math notranslate nohighlight">\(\datafidname\)</span> at <span class="math notranslate nohighlight">\(x\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.tensor</em>) – Variable <span class="math notranslate nohighlight">\(x\)</span> at which the gradient is computed.</p></li>
<li><p><strong>y</strong> (<em>torch.tensor</em>) – Data <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
<li><p><strong>physics</strong> (<a class="reference internal" href="deepinv.physics.Physics.html#deepinv.physics.Physics" title="deepinv.physics.Physics"><em>deepinv.physics.Physics</em></a>) – physics model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.tensor) gradient <span class="math notranslate nohighlight">\(\nabla_x\datafid{x}{y}\)</span>, computed in <span class="math notranslate nohighlight">\(x\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.DataFidelity.grad_d">
<span class="sig-name descname"><span class="pre">grad_d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/data_fidelity.html#DataFidelity.grad_d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.DataFidelity.grad_d" title="Link to this definition"></a></dt>
<dd><p>Computes the gradient <span class="math notranslate nohighlight">\(\nabla_u\distance{u}{y}\)</span>, computed in <span class="math notranslate nohighlight">\(u\)</span>. Note that this is the gradient of
<span class="math notranslate nohighlight">\(\distancename\)</span> and not <span class="math notranslate nohighlight">\(\datafidname\)</span>. By default, the gradient is computed using automatic differentiation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>torch.tensor</em>) – Variable <span class="math notranslate nohighlight">\(u\)</span> at which the gradient is computed.</p></li>
<li><p><strong>y</strong> (<em>torch.tensor</em>) – Data <span class="math notranslate nohighlight">\(y\)</span> of the same dimension as <span class="math notranslate nohighlight">\(u\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.tensor) gradient of <span class="math notranslate nohighlight">\(d\)</span> in <span class="math notranslate nohighlight">\(u\)</span>, i.e. <span class="math notranslate nohighlight">\(\nabla_u\distance{u}{y}\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.DataFidelity.prox">
<span class="sig-name descname"><span class="pre">prox</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">physics</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stepsize_inter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/data_fidelity.html#DataFidelity.prox"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.DataFidelity.prox" title="Link to this definition"></a></dt>
<dd><p>Calculates the proximity operator of <span class="math notranslate nohighlight">\(\datafidname\)</span> at <span class="math notranslate nohighlight">\(x\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.tensor</em>) – Variable <span class="math notranslate nohighlight">\(x\)</span> at which the proximity operator is computed.</p></li>
<li><p><strong>y</strong> (<em>torch.tensor</em>) – Data <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
<li><p><strong>physics</strong> (<a class="reference internal" href="deepinv.physics.Physics.html#deepinv.physics.Physics" title="deepinv.physics.Physics"><em>deepinv.physics.Physics</em></a>) – physics model.</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – stepsize of the proximity operator.</p></li>
<li><p><strong>stepsize_inter</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – stepsize used for internal gradient descent</p></li>
<li><p><strong>max_iter_inter</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#int" title="(in Python v3.4)"><em>int</em></a>) – maximal number of iterations for internal gradient descent.</p></li>
<li><p><strong>tol_inter</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – internal gradient descent has converged when the L2 distance between two consecutive iterates is smaller than tol_inter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.tensor) proximity operator <span class="math notranslate nohighlight">\(\operatorname{prox}_{\gamma \datafidname}(x)\)</span>, computed in <span class="math notranslate nohighlight">\(x\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.DataFidelity.prox_conjugate">
<span class="sig-name descname"><span class="pre">prox_conjugate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">physics</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/data_fidelity.html#DataFidelity.prox_conjugate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.DataFidelity.prox_conjugate" title="Link to this definition"></a></dt>
<dd><p>Calculates the proximity operator of the convex conjugate <span class="math notranslate nohighlight">\((\lambda \datafidname)^*\)</span> at <span class="math notranslate nohighlight">\(x\)</span>,
using the Moreau formula.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function is only valid for convex <span class="math notranslate nohighlight">\(\datafidname\)</span>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.tensor</em>) – Variable <span class="math notranslate nohighlight">\(x\)</span> at which the proximity operator is computed.</p></li>
<li><p><strong>y</strong> (<em>torch.tensor</em>) – Data <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
<li><p><strong>physics</strong> (<a class="reference internal" href="deepinv.physics.Physics.html#deepinv.physics.Physics" title="deepinv.physics.Physics"><em>deepinv.physics.Physics</em></a>) – physics model.</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – stepsize of the proximity operator.</p></li>
<li><p><strong>lamb</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – math:<cite>lambda</cite> parameter in front of <span class="math notranslate nohighlight">\(f\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.tensor) proximity operator <span class="math notranslate nohighlight">\(\operatorname{prox}_{\gamma (\lambda \datafidname)^*}(x)\)</span>,
computed in <span class="math notranslate nohighlight">\(x\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.DataFidelity.prox_d">
<span class="sig-name descname"><span class="pre">prox_d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stepsize_inter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/data_fidelity.html#DataFidelity.prox_d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.DataFidelity.prox_d" title="Link to this definition"></a></dt>
<dd><p>Computes the proximity operator <span class="math notranslate nohighlight">\(\operatorname{prox}_{\gamma\distance{\cdot}{y}}(u)\)</span>, computed in <span class="math notranslate nohighlight">\(u\)</span>. Note
that this is the proximity operator of <span class="math notranslate nohighlight">\(\distancename\)</span> and not <span class="math notranslate nohighlight">\(\datafidname\)</span>. By default, the proximity operator is computed using internal gradient descent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>torch.tensor</em>) – Variable <span class="math notranslate nohighlight">\(u\)</span> at which the proximity operator is computed.</p></li>
<li><p><strong>y</strong> (<em>torch.tensor</em>) – Data <span class="math notranslate nohighlight">\(y\)</span> of the same dimension as <span class="math notranslate nohighlight">\(u\)</span>.</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – stepsize of the proximity operator.</p></li>
<li><p><strong>stepsize_inter</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – stepsize used for internal gradient descent</p></li>
<li><p><strong>max_iter_inter</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#int" title="(in Python v3.4)"><em>int</em></a>) – maximal number of iterations for internal gradient descent.</p></li>
<li><p><strong>tol_inter</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – internal gradient descent has converged when the L2 distance between two consecutive iterates is smaller than tol_inter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.tensor) proximity operator <span class="math notranslate nohighlight">\(\operatorname{prox}_{\gamma\distance{\cdot}{y}}(u)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepinv.optim.DataFidelity.prox_d_conjugate">
<span class="sig-name descname"><span class="pre">prox_d_conjugate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/deepinv/optim/data_fidelity.html#DataFidelity.prox_d_conjugate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deepinv.optim.DataFidelity.prox_d_conjugate" title="Link to this definition"></a></dt>
<dd><p>Calculates the proximity operator of the convex conjugate <span class="math notranslate nohighlight">\((\lambda \distancename)^*\)</span> at <span class="math notranslate nohighlight">\(u\)</span>,
using the Moreau formula.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function is only valid for convex <span class="math notranslate nohighlight">\(\distancename\)</span>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>torch.tensor</em>) – Variable <span class="math notranslate nohighlight">\(u\)</span> at which the proximity operator is computed.</p></li>
<li><p><strong>y</strong> (<em>torch.tensor</em>) – Data <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
<li><p><strong>gamma</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – stepsize of the proximity operator.</p></li>
<li><p><strong>lamb</strong> (<a class="reference external" href="https://docs.python.org/3.4/library/functions.html#float" title="(in Python v3.4)"><em>float</em></a>) – math:<cite>lambda</cite> parameter in front of <span class="math notranslate nohighlight">\(\distancename\)</span></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(torch.tensor) proximity operator <span class="math notranslate nohighlight">\(\operatorname{prox}_{\gamma (\lambda \distancename)^*}(x)\)</span>,
computed in <span class="math notranslate nohighlight">\(x\)</span>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-datafidelity">
<span id="sphx-glr-backref-deepinv-optim-datafidelity"></span><h2>Examples using <code class="docutils literal notranslate"><span class="pre">DataFidelity</span></code>:<a class="headerlink" href="#examples-using-datafidelity" title="Link to this heading"></a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we show how to solve a deblurring inverse problem using an explicit prior."><img alt="" src="../_images/sphx_glr_demo_custom_prior_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_custom_prior.html#sphx-glr-auto-examples-basics-demo-custom-prior-py"><span class="std std-ref">Image deblurring with custom deep explicit prior.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image deblurring with custom deep explicit prior.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Models can be saved and loaded in the same way as in PyTorch. In this example, we show how to d..."><img alt="" src="../_images/sphx_glr_demo_loading_thumb.png" />
<p><a class="reference internal" href="../auto_examples/basics/demo_loading.html#sphx-glr-auto-examples-basics-demo-loading-py"><span class="std std-ref">Saving and loading models</span></a></p>
  <div class="sphx-glr-thumbnail-title">Saving and loading models</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use a standart PnP algorithm with DnCNN denoiser for computed tomogra..."><img alt="" src="../_images/sphx_glr_demo_vanilla_PnP_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_vanilla_PnP.html#sphx-glr-auto-examples-plug-and-play-demo-vanilla-pnp-py"><span class="std std-ref">Vanilla PnP for computed tomography (CT).</span></a></p>
  <div class="sphx-glr-thumbnail-title">Vanilla PnP for computed tomography (CT).</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use the DPIR method to solve a PnP image deblurring problem. The DPIR..."><img alt="" src="../_images/sphx_glr_demo_PnP_DPIR_deblur_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_PnP_DPIR_deblur.html#sphx-glr-auto-examples-plug-and-play-demo-pnp-dpir-deblur-py"><span class="std std-ref">DPIR method for PnP image deblurring.</span></a></p>
  <div class="sphx-glr-thumbnail-title">DPIR method for PnP image deblurring.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We use as plug-in denoiser the Gradient-Step Denoiser (GSPnP) which provides an explicit prior."><img alt="" src="../_images/sphx_glr_demo_RED_GSPnP_SR_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_RED_GSPnP_SR.html#sphx-glr-auto-examples-plug-and-play-demo-red-gspnp-sr-py"><span class="std std-ref">Regularization by Denoising (RED) for Super-Resolution.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Regularization by Denoising (RED) for Super-Resolution.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to define your own optimization algorithm. For example, here, we impleme..."><img alt="" src="../_images/sphx_glr_demo_PnP_custom_optim_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plug-and-play/demo_PnP_custom_optim.html#sphx-glr-auto-examples-plug-and-play-demo-pnp-custom-optim-py"><span class="std std-ref">PnP with custom optimization algorithm (Condat-Vu Primal-Dual)</span></a></p>
  <div class="sphx-glr-thumbnail-title">PnP with custom optimization algorithm (Condat-Vu Primal-Dual)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This code shows you how to use sampling algorithms to quantify uncertainty of a reconstruction ..."><img alt="" src="../_images/sphx_glr_demo_sampling_thumb.png" />
<p><a class="reference internal" href="../auto_examples/sampling/demo_sampling.html#sphx-glr-auto-examples-sampling-demo-sampling-py"><span class="std std-ref">Uncertainty quantification with PnP-ULA.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Uncertainty quantification with PnP-ULA.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This code shows how to build your custom sampling kernel. Here we build a preconditioned Unadju..."><img alt="" src="../_images/sphx_glr_demo_custom_kernel_thumb.png" />
<p><a class="reference internal" href="../auto_examples/sampling/demo_custom_kernel.html#sphx-glr-auto-examples-sampling-demo-custom-kernel-py"><span class="std std-ref">Building your custom sampling algorithm.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Building your custom sampling algorithm.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we will go over the steps in the Diffusion Posterior Sampling (DPS) algorithm..."><img alt="" src="../_images/sphx_glr_demo_dps_thumb.png" />
<p><a class="reference internal" href="../auto_examples/sampling/demo_dps.html#sphx-glr-auto-examples-sampling-demo-dps-py"><span class="std std-ref">Implementing DPS</span></a></p>
  <div class="sphx-glr-thumbnail-title">Implementing DPS</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we revisit the implementation of the DiffPIR diffusion algorithm for image re..."><img alt="" src="../_images/sphx_glr_demo_diffpir_thumb.png" />
<p><a class="reference internal" href="../auto_examples/sampling/demo_diffpir.html#sphx-glr-auto-examples-sampling-demo-diffpir-py"><span class="std std-ref">Implementing DiffPIR</span></a></p>
  <div class="sphx-glr-thumbnail-title">Implementing DiffPIR</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows you how to train a reconstruction network for an MRI inverse problem on a fu..."><img alt="" src="../_images/sphx_glr_demo_equivariant_imaging_thumb.png" />
<p><a class="reference internal" href="../auto_examples/self-supervised-learning/demo_equivariant_imaging.html#sphx-glr-auto-examples-self-supervised-learning-demo-equivariant-imaging-py"><span class="std std-ref">Self-supervised learning with Equivariant Imaging for MRI.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Self-supervised learning with Equivariant Imaging for MRI.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to implement the LISTA algorithm for a compressed sensing problem. In a ..."><img alt="" src="../_images/sphx_glr_demo_LISTA_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_LISTA.html#sphx-glr-auto-examples-unfolded-demo-lista-py"><span class="std std-ref">Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing</span></a></p>
  <div class="sphx-glr-thumbnail-title">Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to implement a learned unrolled proximal gradient descent algorithm with..."><img alt="" src="../_images/sphx_glr_demo_custom_prior_unfolded_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_custom_prior_unfolded.html#sphx-glr-auto-examples-unfolded-demo-custom-prior-unfolded-py"><span class="std std-ref">Learned iterative custom prior</span></a></p>
  <div class="sphx-glr-thumbnail-title">Learned iterative custom prior</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This is a simple example to show how to use vanilla unfolded Plug-and-Play. The DnCNN denoiser ..."><img alt="" src="../_images/sphx_glr_demo_vanilla_unfolded_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_vanilla_unfolded.html#sphx-glr-auto-examples-unfolded-demo-vanilla-unfolded-py"><span class="std std-ref">Vanilla Unfolded algorithm for super-resolution</span></a></p>
  <div class="sphx-glr-thumbnail-title">Vanilla Unfolded algorithm for super-resolution</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This a toy example to show you how to use DEQ to solve a deblurring problem.  Note that this is..."><img alt="" src="../_images/sphx_glr_demo_DEQ_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_DEQ.html#sphx-glr-auto-examples-unfolded-demo-deq-py"><span class="std std-ref">Deep Equilibrium (DEQ) algorithms for image deblurring</span></a></p>
  <div class="sphx-glr-thumbnail-title">Deep Equilibrium (DEQ) algorithms for image deblurring</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Adler, Jonas, and Ozan Öktem.  &quot;Learned primal-dual reconstruction.&quot;  IEEE transactions on medi..."><img alt="" src="../_images/sphx_glr_demo_learned_primal_dual_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_learned_primal_dual.html#sphx-glr-auto-examples-unfolded-demo-learned-primal-dual-py"><span class="std std-ref">Learned Primal-Dual algorithm for CT scan.</span></a></p>
  <div class="sphx-glr-thumbnail-title">Learned Primal-Dual algorithm for CT scan.</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Image inpainting consists in solving y = Ax where A is a mask operator. This problem can be ref..."><img alt="" src="../_images/sphx_glr_demo_unfolded_constrained_LISTA_thumb.png" />
<p><a class="reference internal" href="../auto_examples/unfolded/demo_unfolded_constrained_LISTA.html#sphx-glr-auto-examples-unfolded-demo-unfolded-constrained-lista-py"><span class="std std-ref">Unfolded Chambolle-Pock for constrained image inpainting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Unfolded Chambolle-Pock for constrained image inpainting</div>
</div></div></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="deepinv.optim.BaseOptim.html" class="btn btn-neutral float-left" title="BaseOptim" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="deepinv.optim.L1.html" class="btn btn-neutral float-right" title="L1" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, DeepInv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEKFKYSGR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NSEKFKYSGR', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>
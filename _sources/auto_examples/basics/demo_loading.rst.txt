
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/basics/demo_loading.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_basics_demo_loading.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_basics_demo_loading.py:


Saving and loading models
====================================================================================================

Models can be saved and loaded in the same way as in PyTorch. In this example, we show how to define, load and save a
model. For the purpose of the example, we choose an unfolded Chambolle Pock algorithm as the model.
The architecture of the model and its training are described
in the `constrained unfolded demo <https://deepinv.github.io/deepinv/auto_examples/unfolded/demo_unfolded_constrained_LISTA.html>`_.

.. GENERATED FROM PYTHON SOURCE LINES 11-21

.. code-block:: default

    from pathlib import Path
    import torch

    import deepinv as dinv
    from deepinv.optim.data_fidelity import IndicatorL2
    from deepinv.optim.prior import PnP
    from deepinv.unfolded import unfolded_builder
    from deepinv.models.denoiser import online_weights_path









.. GENERATED FROM PYTHON SOURCE LINES 22-25

Setup paths for data loading and results.
---------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 25-34

.. code-block:: default


    BASE_DIR = Path(".")
    ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
    DATA_DIR = BASE_DIR / "measurements"
    RESULTS_DIR = BASE_DIR / "results"
    DEG_DIR = BASE_DIR / "degradations"
    CKPT_DIR = BASE_DIR / "ckpts"









.. GENERATED FROM PYTHON SOURCE LINES 35-39

Define a forward operator
--------------------------------------------
We define a simple inpainting operator with 50% of missing pixels.


.. GENERATED FROM PYTHON SOURCE LINES 39-50

.. code-block:: default


    n_channels = 3
    img_size = 32
    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"

    # Define the physics model
    physics = dinv.physics.Inpainting(
        (n_channels, img_size, img_size), mask=0.5, device=device
    )









.. GENERATED FROM PYTHON SOURCE LINES 51-55

Define a model
--------------------------------------------
For the purpose of this example, we define a rather complex model that consists an unfolded Chambolle-Pock algorithm.


.. GENERATED FROM PYTHON SOURCE LINES 55-118

.. code-block:: default



    # Select the data fidelity term
    data_fidelity = IndicatorL2(radius=0.0)

    # Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.
    # If the prior is initialized with a list of length max_iter,
    # then a distinct weight is trained for each CP iteration.
    # For fixed trained model prior across iterations, initialize with a single model.

    level = 3
    max_iter = 30 if torch.cuda.is_available() else 20  # Number of unrolled iterations

    prior = [
        PnP(denoiser=dinv.models.WaveletPrior(wv="db8", level=level, device=device))
        for i in range(max_iter)
    ]

    # Unrolled optimization algorithm parameters
    lamb = [
        1.0
    ] * max_iter  # initialization of the regularization parameter. A distinct lamb is trained for each iteration.
    stepsize = [
        1.0
    ] * max_iter  # initialization of the stepsizes. A distinct stepsize is trained for each iteration.
    sigma_denoiser = [0.01 * torch.ones(level, 3)] * max_iter

    sigma = 1.0  # stepsize for Chambolle-Pock

    params_algo = {
        "stepsize": stepsize,
        "g_param": sigma_denoiser,
        "lambda": lamb,
        "sigma": sigma,
        "K": physics.A,
        "K_adjoint": physics.A_adjoint,
    }

    trainable_params = [
        "g_param",
        "stepsize",
    ]  # define which parameters from 'params_algo' are trainable


    # Because the CP algorithm uses more than 2 variables, we need to define a custom initialization.
    def custom_init_CP(y, physics):
        x_init = physics.A_adjoint(y)
        u_init = y
        return {"est": (x_init, x_init, u_init)}


    # Define the unfolded trainable model.
    model = unfolded_builder(
        "CP",
        trainable_params=trainable_params,
        params_algo=params_algo,
        data_fidelity=data_fidelity,
        max_iter=max_iter,
        prior=prior,
        g_first=False,
        custom_init=custom_init_CP,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/deepinv/deepinv/deepinv/unfolded/unfolded.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
      [nn.Parameter(torch.tensor(el).to(device)) for el in param_value]




.. GENERATED FROM PYTHON SOURCE LINES 119-121

-------------------
We can save the trained model following the standard PyTorch procedure.

.. GENERATED FROM PYTHON SOURCE LINES 121-126

.. code-block:: default


    # Save the model

    torch.save(model.state_dict(), CKPT_DIR / "inpainting/model_nontrained.pth")








.. GENERATED FROM PYTHON SOURCE LINES 127-130

-------------------
Similarly, we can load our trained unfolded architecture following the standard PyTorch procedure.
This network was trained in the demo :ref:`sphx_glr_auto_examples_unfolded_demo_unfolded_constrained_LISTA.py`.

.. GENERATED FROM PYTHON SOURCE LINES 130-189

.. code-block:: default


    # Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.
    # If the prior is initialized with a list of length max_iter,
    # then a distinct weight is trained for each PGD iteration.
    # For fixed trained model prior across iterations, initialize with a single model.

    prior_new = [
        PnP(denoiser=dinv.models.WaveletPrior(wv="db8", level=level, device=device))
        for i in range(max_iter)
    ]

    # Unrolled optimization algorithm parameters
    lamb = [
        1.0
    ] * max_iter  # initialization of the regularization parameter. A distinct lamb is trained for each iteration.
    stepsize = [
        1.0
    ] * max_iter  # initialization of the stepsizes. A distinct stepsize is trained for each iteration.
    sigma_denoiser = [0.01 * torch.ones(level, 3)] * max_iter

    sigma = 1.0  # stepsize for Chambolle-Pock

    params_algo_new = {
        "stepsize": stepsize,
        "g_param": sigma_denoiser,
        "lambda": lamb,
        "sigma": sigma,
        "K": physics.A,
        "K_adjoint": physics.A_adjoint,
    }

    model_new = unfolded_builder(
        "CP",
        trainable_params=trainable_params,
        params_algo=params_algo_new,
        data_fidelity=data_fidelity,
        max_iter=max_iter,
        prior=prior_new,
        g_first=False,
        custom_init=custom_init_CP,
    )
    print(
        "Parameter model_new.params_algo.g_param[0] at init: \n",
        model_new.params_algo.g_param[0],
    )


    # load a state_dict checkpoint
    url = online_weights_path() + "demo_unfolded_CP_2.pth"
    ckpt_state_dict = torch.hub.load_state_dict_from_url(
        url, map_location=lambda storage, loc: storage, file_name="demo_unfolded_CP_2.pth"
    )
    # load a state_dict checkpoint
    model_new.load_state_dict(ckpt_state_dict)

    print(
        "Parameter model_new.params_algo.g_param[0] after loading: \n",
        model_new.params_algo.g_param[0],
    )




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Parameter model_new.params_algo.g_param[0] at init: 
     Parameter containing:
    tensor([[0.0100, 0.0100, 0.0100],
            [0.0100, 0.0100, 0.0100],
            [0.0100, 0.0100, 0.0100]], requires_grad=True)
    Downloading: "https://mycore.core-cloud.net/index.php/s/9EzDqcJxQUJKYul/download?path=%2Fweights&files=demo_unfolded_CP_2.pth" to /home/runner/.cache/torch/hub/checkpoints/demo_unfolded_CP_2.pth
      0%|          | 0.00/66.8k [00:00<?, ?B/s]    100%|██████████| 66.8k/66.8k [00:00<00:00, 761kB/s]
    Parameter model_new.params_algo.g_param[0] after loading: 
     Parameter containing:
    tensor([[0.0545, 0.0512, 0.0481],
            [0.0512, 0.0484, 0.0526],
            [0.0535, 0.0481, 0.0427]], requires_grad=True)





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 1.416 seconds)


.. _sphx_glr_download_auto_examples_basics_demo_loading.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_loading.py <demo_loading.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_loading.ipynb <demo_loading.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

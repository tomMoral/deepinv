
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/self-supervised-learning/demo_sure_denoising.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_self-supervised-learning_demo_sure_denoising.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_self-supervised-learning_demo_sure_denoising.py:


Self-supervised denoising with the SURE loss.
====================================================================================================

This example shows you how to train a denoiser network in a fully self-supervised way,
i.e., using noisy images only via the SURE loss, which exploits knowledge about the noise distribution.

The SURE loss for Poisson denoising acts as an unbiased estimator of the supervised loss and is computed as:


.. math::

    \frac{1}{m}\|y-\inverse{y}\|_2^2-\frac{\gamma}{m} 1^{\top}y
    +\frac{2\gamma}{m\tau}(b\odot y)^{\top} \left(\inverse{y+\tau b}-\inverse{y}\right)

where :math:`R` is the trainable network, :math:`y` is the noisy image with :math:`m` pixels,
:math:`b` is a Bernoulli random variable taking values of -1 and 1 each with a probability of 0.5,
:math:`\tau` is a small positive number, and :math:`\odot` is an elementwise multiplication.

.. GENERATED FROM PYTHON SOURCE LINES 22-31

.. code-block:: default


    import deepinv as dinv
    from torch.utils.data import DataLoader
    import torch
    from pathlib import Path
    from torchvision import transforms, datasets
    from deepinv.training_utils import train, test
    from deepinv.models.denoiser import online_weights_path








.. GENERATED FROM PYTHON SOURCE LINES 32-35

Setup paths for data loading and results.
---------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 35-48

.. code-block:: default


    BASE_DIR = Path(".")
    ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
    DATA_DIR = BASE_DIR / "measurements"
    RESULTS_DIR = BASE_DIR / "results"
    DEG_DIR = BASE_DIR / "degradations"
    CKPT_DIR = BASE_DIR / "ckpts"

    # Set the global random seed from pytorch to ensure reproducibility of the example.
    torch.manual_seed(0)

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"








.. GENERATED FROM PYTHON SOURCE LINES 49-53

Load base image datasets
----------------------------------------------------------------------------------
In this example, we use the MNIST dataset as the base image dataset.


.. GENERATED FROM PYTHON SOURCE LINES 53-66

.. code-block:: default


    operation = "denoising"
    train_dataset_name = "MNIST"

    transform = transforms.Compose([transforms.ToTensor()])

    train_dataset = datasets.MNIST(
        root="../datasets/", train=True, transform=transform, download=True
    )
    test_dataset = datasets.MNIST(
        root="../datasets/", train=False, transform=transform, download=True
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../datasets/MNIST/raw/train-images-idx3-ubyte.gz
      0%|          | 0/9912422 [00:00<?, ?it/s]    100%|██████████| 9912422/9912422 [00:00<00:00, 163659418.06it/s]
    Extracting ../datasets/MNIST/raw/train-images-idx3-ubyte.gz to ../datasets/MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../datasets/MNIST/raw/train-labels-idx1-ubyte.gz
      0%|          | 0/28881 [00:00<?, ?it/s]    100%|██████████| 28881/28881 [00:00<00:00, 153530663.91it/s]
    Extracting ../datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ../datasets/MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../datasets/MNIST/raw/t10k-images-idx3-ubyte.gz
      0%|          | 0/1648877 [00:00<?, ?it/s]    100%|██████████| 1648877/1648877 [00:00<00:00, 55413132.35it/s]
    Extracting ../datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ../datasets/MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz
      0%|          | 0/4542 [00:00<?, ?it/s]    100%|██████████| 4542/4542 [00:00<00:00, 29129248.88it/s]
    Extracting ../datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../datasets/MNIST/raw





.. GENERATED FROM PYTHON SOURCE LINES 67-76

Generate a dataset of noisy images
----------------------------------------------------------------------------------

We generate a dataset of noisy images corrupted by Poisson noise.

.. note::

      We use a subset of the whole training set to reduce the computational load of the example.
      We recommend to use the whole set by setting ``n_images_max=None`` to get the best results.

.. GENERATED FROM PYTHON SOURCE LINES 76-104

.. code-block:: default


    # defined physics
    physics = dinv.physics.Denoising(dinv.physics.PoissonNoise(0.1))

    # Use parallel dataloader if using a GPU to fasten training,
    # otherwise, as all computes are on CPU, use synchronous data loading.
    num_workers = 4 if torch.cuda.is_available() else 0

    n_images_max = (
        100 if torch.cuda.is_available() else 5
    )  # number of images used for training

    measurement_dir = DATA_DIR / train_dataset_name / operation
    deepinv_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_dataset,
        test_dataset=test_dataset,
        physics=physics,
        device=device,
        save_dir=measurement_dir,
        train_datapoints=n_images_max,
        test_datapoints=n_images_max,
        num_workers=num_workers,
        dataset_filename="demo_sure",
    )

    train_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)
    test_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Computing train measurement vectors from base dataset...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 250.11it/s]
    Computing test measurement vectors from base dataset...
      0%|          | 0/2 [00:00<?, ?it/s]    100%|██████████| 2/2 [00:00<00:00, 703.57it/s]
    Dataset has been saved in measurements/MNIST/denoising




.. GENERATED FROM PYTHON SOURCE LINES 105-109

Set up the denoiser network
---------------------------------------------------------------

We use a simple U-Net architecture with 2 scales as the denoiser network.

.. GENERATED FROM PYTHON SOURCE LINES 109-115

.. code-block:: default


    model = dinv.models.ArtifactRemoval(
        dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device)
    )









.. GENERATED FROM PYTHON SOURCE LINES 116-129

Set up the training parameters
--------------------------------------------
We set :class:`deepinv.loss.SurePoissonLoss` as the training loss.

.. note::

      There are SURE losses for various noise distributions. See also :class:`deepinv.loss.SureGaussianLoss`
      for Gaussian noise and :class:`deepinv.loss.SurePGLoss` for mixed Poisson-Gaussian noise.

.. note::

      We use a pretrained model to reduce training time. You can get the same results by training from scratch
      for 10 epochs.

.. GENERATED FROM PYTHON SOURCE LINES 129-150

.. code-block:: default


    epochs = 1  # choose training epochs
    learning_rate = 5e-4
    batch_size = 32 if torch.cuda.is_available() else 1

    # choose self-supervised training loss
    loss = dinv.loss.SurePoissonLoss(gain=0.1)

    # choose optimizer and scheduler
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8) + 1)

    # start with a pretrained model to reduce training time
    url = online_weights_path() + "ckp_10_demo_sure.pth"
    ckpt = torch.hub.load_state_dict_from_url(
        url, map_location=lambda storage, loc: storage, file_name="ckp_10_demo_sure.pth"
    )
    # load a checkpoint to reduce training time
    model.load_state_dict(ckpt["state_dict"])
    optimizer.load_state_dict(ckpt["optimizer"])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://mycore.core-cloud.net/index.php/s/9EzDqcJxQUJKYul/download?path=%2Fweights&files=ckp_10_demo_sure.pth" to /home/runner/.cache/torch/hub/checkpoints/ckp_10_demo_sure.pth
      0%|          | 0.00/5.14M [00:00<?, ?B/s]      1%|▏         | 72.0k/5.14M [00:00<00:07, 677kB/s]      4%|▍         | 200k/5.14M [00:00<00:05, 991kB/s]       9%|▉         | 464k/5.14M [00:00<00:02, 1.70MB/s]     14%|█▎        | 720k/5.14M [00:00<00:02, 1.98MB/s]     19%|█▉        | 1.00M/5.14M [00:00<00:01, 2.36MB/s]     25%|██▍       | 1.27M/5.14M [00:00<00:01, 2.46MB/s]     30%|██▉       | 1.54M/5.14M [00:00<00:01, 2.58MB/s]     36%|███▌      | 1.83M/5.14M [00:00<00:01, 2.72MB/s]     41%|████      | 2.09M/5.14M [00:01<00:03, 877kB/s]      45%|████▍     | 2.29M/5.14M [00:01<00:03, 925kB/s]     49%|████▉     | 2.52M/5.14M [00:01<00:02, 1.12MB/s]     53%|█████▎    | 2.74M/5.14M [00:02<00:01, 1.32MB/s]     59%|█████▊    | 3.02M/5.14M [00:02<00:01, 1.61MB/s]     64%|██████▍   | 3.29M/5.14M [00:02<00:01, 1.87MB/s]     69%|██████▉   | 3.55M/5.14M [00:02<00:00, 2.02MB/s]     74%|███████▍  | 3.82M/5.14M [00:02<00:00, 2.23MB/s]     80%|███████▉  | 4.09M/5.14M [00:02<00:00, 2.38MB/s]     85%|████████▌ | 4.37M/5.14M [00:02<00:00, 2.50MB/s]     90%|█████████ | 4.63M/5.14M [00:02<00:00, 2.57MB/s]     95%|█████████▌| 4.90M/5.14M [00:02<00:00, 2.62MB/s]    100%|██████████| 5.14M/5.14M [00:02<00:00, 1.84MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 151-155

Train the network
--------------------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 155-181

.. code-block:: default


    verbose = True  # print training information
    wandb_vis = False  # plot curves and images in Weight&Bias

    train_dataloader = DataLoader(
        train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True
    )
    test_dataloader = DataLoader(
        test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False
    )

    train(
        model=model,
        train_dataloader=train_dataloader,
        eval_dataloader=test_dataloader,
        epochs=epochs,
        scheduler=scheduler,
        losses=loss,
        physics=physics,
        optimizer=optimizer,
        device=device,
        save_path=str(CKPT_DIR / operation),
        verbose=verbose,
        wandb_vis=wandb_vis,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 444737 trainable parameters
            23-10-24-10:18:32       [1/1]   loss=1.80e-03   Loss_SurePoisson=1.80e-03       Train_psnr_model=24.46  Eval_psnr_model=23.59   

    ArtifactRemoval(
      (backbone_net): UNet(
        (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (Conv1): Sequential(
          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Conv2): Sequential(
          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BFBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BFBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Up2): Sequential(
          (0): Upsample(scale_factor=2.0, mode='nearest')
          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (2): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
        )
        (Up_conv2): Sequential(
          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )



.. GENERATED FROM PYTHON SOURCE LINES 182-186

Test the network
--------------------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 186-199

.. code-block:: default


    plot_images = True

    test(
        model=model,
        test_dataloader=test_dataloader,
        physics=physics,
        device=device,
        plot_images=plot_images,
        save_folder=RESULTS_DIR / "sure" / operation,
        verbose=verbose,
        wandb_vis=wandb_vis,
    )



.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_sure_denoising_001.png
   :alt: Input, Linear, Recons., GT
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_sure_denoising_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Processing data of operator 1 out of 1
      0%|          | 0/5 [00:00<?, ?it/s]     20%|██        | 1/5 [00:01<00:05,  1.41s/it]    100%|██████████| 5/5 [00:01<00:00,  4.33it/s]    100%|██████████| 5/5 [00:01<00:00,  3.32it/s]
    Test PSNR: Linear rec.: 19.35+-1.79 dB | Model: 23.59+-1.82 dB. 

    (23.588863372802734, 1.8207126642763243, 19.346026992797853, 1.7863424937640642)




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 38.251 seconds)


.. _sphx_glr_download_auto_examples_self-supervised-learning_demo_sure_denoising.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_sure_denoising.py <demo_sure_denoising.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_sure_denoising.ipynb <demo_sure_denoising.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

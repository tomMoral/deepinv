
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/self-supervised-learning/demo_n2n_denoising.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_self-supervised-learning_demo_n2n_denoising.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_self-supervised-learning_demo_n2n_denoising.py:


Self-supervised denoising with the Neighbor2Neighbor loss.
====================================================================================================

This example shows you how to train a denoiser network in a fully self-supervised way,
i.e., using noisy images only via the Neighbor2Neighbor loss, which exploits the local correlation of natural images.

The Neighbor2Neighbor loss is presented in `"Neighbor2Neighbor: Self-Supervised Denoising from Single Noisy Images"
<https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Neighbor2Neighbor_Self-Supervised_Denoising_From_Single_Noisy_Images_CVPR_2021_paper.pdf>`_
and is defined as:

.. math::

    \| A_2 y - R(A_1 y)\|^2 + \gamma \| A_2 y - R(A_1 y) - (A_2 R(y) - A_1 R(y))\|^2

where :math:`A_1` and :math:`A_2` are two masks, each choosing a different neighboring map,
:math:`R` is the trainable denoiser network, :math:`\gamma>0` is a regularization parameter
and no gradient is propagated when computing :math:`R(y)`.

.. GENERATED FROM PYTHON SOURCE LINES 22-31

.. code-block:: default


    import deepinv as dinv
    from torch.utils.data import DataLoader
    import torch
    from pathlib import Path
    from torchvision import transforms, datasets
    from deepinv.training_utils import train, test
    from deepinv.models.denoiser import online_weights_path








.. GENERATED FROM PYTHON SOURCE LINES 32-35

Setup paths for data loading and results.
---------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 35-48

.. code-block:: default


    BASE_DIR = Path(".")
    ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
    DATA_DIR = BASE_DIR / "measurements"
    RESULTS_DIR = BASE_DIR / "results"
    DEG_DIR = BASE_DIR / "degradations"
    CKPT_DIR = BASE_DIR / "ckpts"

    # Set the global random seed from pytorch to ensure reproducibility of the example.
    torch.manual_seed(0)

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"








.. GENERATED FROM PYTHON SOURCE LINES 49-53

Load base image datasets
----------------------------------------------------------------------------------
In this example, we use the MNIST dataset as the base image dataset.


.. GENERATED FROM PYTHON SOURCE LINES 53-66

.. code-block:: default


    operation = "denoising"
    train_dataset_name = "MNIST"

    transform = transforms.Compose([transforms.ToTensor()])

    train_dataset = datasets.MNIST(
        root="../datasets/", train=True, transform=transform, download=True
    )
    test_dataset = datasets.MNIST(
        root="../datasets/", train=False, transform=transform, download=True
    )








.. GENERATED FROM PYTHON SOURCE LINES 67-76

Generate a dataset of noisy images
----------------------------------------------------------------------------------

We generate a dataset of noisy images corrupted by Poisson noise.

.. note::

      We use a subset of the whole training set to reduce the computational load of the example.
      We recommend to use the whole set by setting ``n_images_max=None`` to get the best results.

.. GENERATED FROM PYTHON SOURCE LINES 76-105

.. code-block:: default


    # defined physics
    physics = dinv.physics.Denoising(dinv.physics.PoissonNoise(0.1))

    # Use parallel dataloader if using a GPU to fasten training,
    # otherwise, as all computes are on CPU, use synchronous data loading.
    num_workers = 4 if torch.cuda.is_available() else 0

    n_images_max = (
        100 if torch.cuda.is_available() else 5
    )  # number of images used for training

    my_dataset_name = "demo_n2n"
    measurement_dir = DATA_DIR / train_dataset_name / operation
    deepinv_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_dataset,
        test_dataset=test_dataset,
        physics=physics,
        device=device,
        save_dir=measurement_dir,
        train_datapoints=n_images_max,
        test_datapoints=n_images_max,
        num_workers=num_workers,
        dataset_filename=str(my_dataset_name),
    )

    train_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)
    test_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Computing train measurement vectors from base dataset...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 317.46it/s]
    Computing test measurement vectors from base dataset...
      0%|          | 0/2 [00:00<?, ?it/s]    100%|██████████| 2/2 [00:00<00:00, 695.23it/s]
    Dataset has been saved in measurements/MNIST/denoising




.. GENERATED FROM PYTHON SOURCE LINES 106-110

Set up the denoiser network
---------------------------------------------------------------

We use a simple U-Net architecture with 2 scales as the denoiser network.

.. GENERATED FROM PYTHON SOURCE LINES 110-116

.. code-block:: default


    model = dinv.models.ArtifactRemoval(
        dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device)
    )









.. GENERATED FROM PYTHON SOURCE LINES 117-125

Set up the training parameters
--------------------------------------------
We set :class:`deepinv.loss.Neighbor2Neighbor` as the training loss.

.. note::

      We use a pretrained model to reduce training time. You can get the same results by training from scratch
      for 50 epochs.

.. GENERATED FROM PYTHON SOURCE LINES 125-146

.. code-block:: default


    epochs = 1  # choose training epochs
    learning_rate = 5e-4
    batch_size = 32 if torch.cuda.is_available() else 1

    # choose self-supervised training loss
    loss = dinv.loss.Neighbor2Neighbor()

    # choose optimizer and scheduler
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8) + 1)

    # start with a pretrained model to reduce training time
    url = online_weights_path() + "ckp_50_demo_n2n.pth"
    ckpt = torch.hub.load_state_dict_from_url(
        url, map_location=lambda storage, loc: storage, file_name="ckp_50_demo_n2n.pth"
    )
    # load a checkpoint to reduce training time
    model.load_state_dict(ckpt["state_dict"])
    optimizer.load_state_dict(ckpt["optimizer"])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://mycore.core-cloud.net/index.php/s/9EzDqcJxQUJKYul/download?path=%2Fweights&files=ckp_50_demo_n2n.pth" to /home/runner/.cache/torch/hub/checkpoints/ckp_50_demo_n2n.pth
      0%|          | 0.00/5.14M [00:00<?, ?B/s]      2%|▏         | 88.0k/5.14M [00:00<00:06, 780kB/s]      5%|▍         | 248k/5.14M [00:00<00:04, 1.12MB/s]     10%|▉         | 504k/5.14M [00:00<00:03, 1.62MB/s]     17%|█▋        | 912k/5.14M [00:00<00:01, 2.51MB/s]     22%|██▏       | 1.15M/5.14M [00:00<00:01, 2.55MB/s]     28%|██▊       | 1.45M/5.14M [00:00<00:01, 2.75MB/s]     34%|███▎      | 1.73M/5.14M [00:00<00:01, 2.46MB/s]     39%|███▉      | 2.02M/5.14M [00:00<00:01, 2.62MB/s]     45%|████▍     | 2.30M/5.14M [00:01<00:01, 2.73MB/s]     51%|█████     | 2.62M/5.14M [00:01<00:00, 2.88MB/s]     57%|█████▋    | 2.91M/5.14M [00:01<00:00, 2.63MB/s]     62%|██████▏   | 3.21M/5.14M [00:01<00:00, 2.76MB/s]     68%|██████▊   | 3.50M/5.14M [00:01<00:00, 2.81MB/s]     75%|███████▍  | 3.84M/5.14M [00:01<00:00, 2.99MB/s]     80%|████████  | 4.13M/5.14M [00:01<00:00, 2.70MB/s]     86%|████████▌ | 4.40M/5.14M [00:01<00:00, 2.72MB/s]     92%|█████████▏| 4.71M/5.14M [00:01<00:00, 2.88MB/s]     98%|█████████▊| 5.05M/5.14M [00:01<00:00, 3.03MB/s]    100%|██████████| 5.14M/5.14M [00:02<00:00, 2.61MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 147-151

Train the network
--------------------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 151-177

.. code-block:: default


    verbose = True  # print training information
    wandb_vis = False  # plot curves and images in Weight&Bias

    train_dataloader = DataLoader(
        train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True
    )
    test_dataloader = DataLoader(
        test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False
    )

    train(
        model=model,
        train_dataloader=train_dataloader,
        eval_dataloader=test_dataloader,
        epochs=epochs,
        scheduler=scheduler,
        losses=loss,
        physics=physics,
        optimizer=optimizer,
        device=device,
        save_path=str(CKPT_DIR / operation),
        verbose=verbose,
        wandb_vis=wandb_vis,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 444737 trainable parameters
            23-10-24-10:18:37       [1/1]   loss=7.04e-02   Loss_neigh2neigh=7.04e-02       Train_psnr_model=24.56  Eval_psnr_model=24.60   

    ArtifactRemoval(
      (backbone_net): UNet(
        (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (Conv1): Sequential(
          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Conv2): Sequential(
          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BFBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BFBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Up2): Sequential(
          (0): Upsample(scale_factor=2.0, mode='nearest')
          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (2): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
        )
        (Up_conv2): Sequential(
          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BFBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
        (Conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )



.. GENERATED FROM PYTHON SOURCE LINES 178-182

Test the network
--------------------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 182-196

.. code-block:: default


    plot_images = True
    method = "neighbor2neighbor"

    test(
        model=model,
        test_dataloader=test_dataloader,
        physics=physics,
        device=device,
        plot_images=plot_images,
        save_folder=RESULTS_DIR / method / operation,
        verbose=verbose,
        wandb_vis=wandb_vis,
    )



.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_n2n_denoising_001.png
   :alt: Input, Linear, Recons., GT
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_n2n_denoising_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Processing data of operator 1 out of 1
      0%|          | 0/5 [00:00<?, ?it/s]     20%|██        | 1/5 [00:01<00:05,  1.38s/it]    100%|██████████| 5/5 [00:01<00:00,  3.45it/s]
    Test PSNR: Linear rec.: 19.35+-1.79 dB | Model: 24.60+-1.50 dB. 

    (24.59684829711914, 1.498270922944005, 19.346026992797853, 1.7863424937640642)




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 4.899 seconds)


.. _sphx_glr_download_auto_examples_self-supervised-learning_demo_n2n_denoising.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_n2n_denoising.py <demo_n2n_denoising.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_n2n_denoising.ipynb <demo_n2n_denoising.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

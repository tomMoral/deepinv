
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/unfolded/demo_DEQ.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_unfolded_demo_DEQ.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_unfolded_demo_DEQ.py:


Deep Equilibrium (DEQ) algorithms for image deblurring
====================================================================================================

This a toy example to show you how to use DEQ to solve a deblurring problem. 
Note that this is a small dataset for training. For optimal results, use a larger dataset.
For visualizing the training, you can use Weight&Bias (wandb) by setting ``wandb_vis=True``.

For now DEQ is only possible with PGD, HQS and GD optimization algorithms. 

.. GENERATED FROM PYTHON SOURCE LINES 12-25

.. code-block:: default


    import deepinv as dinv
    from pathlib import Path
    import torch
    from torch.utils.data import DataLoader
    from deepinv.models import DnCNN
    from deepinv.optim.data_fidelity import L2
    from deepinv.optim.prior import PnP
    from deepinv.unfolded import DEQ_builder
    from deepinv.training_utils import train, test
    from torchvision import transforms
    from deepinv.utils.demo import load_dataset








.. GENERATED FROM PYTHON SOURCE LINES 26-29

Setup paths for data loading and results.
----------------------------------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 29-41

.. code-block:: default


    BASE_DIR = Path(".")
    ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
    DATA_DIR = BASE_DIR / "measurements"
    RESULTS_DIR = BASE_DIR / "results"
    CKPT_DIR = BASE_DIR / "ckpts"

    # Set the global random seed from pytorch to ensure reproducibility of the example.
    torch.manual_seed(0)

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"








.. GENERATED FROM PYTHON SOURCE LINES 42-45

Load base image datasets and degradation operators.
----------------------------------------------------------------------------------------
In this example, we use the CBSD500 dataset and the Set3C dataset for testing.

.. GENERATED FROM PYTHON SOURCE LINES 45-68

.. code-block:: default


    img_size = 32
    n_channels = 3  # 3 for color images, 1 for gray-scale images
    operation = "deblurring"
    # For simplicity, we use a small dataset for training.
    # To be replaced for optimal results. For example, you can use the larger "drunet" dataset.
    train_dataset_name = "CBSD500"
    test_dataset_name = "set3c"
    # Generate training and evaluation datasets in HDF5 folders and load them.
    test_transform = transforms.Compose(
        [transforms.CenterCrop(img_size), transforms.ToTensor()]
    )
    train_transform = transforms.Compose(
        [transforms.RandomCrop(img_size), transforms.ToTensor()]
    )
    train_base_dataset = load_dataset(
        train_dataset_name, ORIGINAL_DATA_DIR, transform=train_transform
    )
    test_base_dataset = load_dataset(
        test_dataset_name, ORIGINAL_DATA_DIR, transform=test_transform
    )









.. GENERATED FROM PYTHON SOURCE LINES 69-72

Generate a dataset of low resolution images and load it.
----------------------------------------------------------------------------------------
We use the Downsampling class from the physics module to generate a dataset of low resolution images.

.. GENERATED FROM PYTHON SOURCE LINES 72-107

.. code-block:: default



    # Use parallel dataloader if using a GPU to fasten training, otherwise, as all computes are on CPU, use synchronous
    # dataloading.
    num_workers = 4 if torch.cuda.is_available() else 0

    # Degradation parameters
    noise_level_img = 0.03

    # Generate the gaussian blur downsampling operator.
    physics = dinv.physics.BlurFFT(
        img_size=(n_channels, img_size, img_size),
        filter=dinv.physics.blur.gaussian_blur(),
        device=device,
        noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),
    )
    my_dataset_name = "demo_DEQ"
    n_images_max = (
        1000 if torch.cuda.is_available() else 10
    )  # maximal number of images used for training
    measurement_dir = DATA_DIR / train_dataset_name / operation
    generated_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_base_dataset,
        test_dataset=test_base_dataset,
        physics=physics,
        device=device,
        save_dir=measurement_dir,
        train_datapoints=n_images_max,
        num_workers=num_workers,
        dataset_filename=str(my_dataset_name),
    )

    train_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)
    test_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Computing train measurement vectors from base dataset...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 44.00it/s]
    Computing test measurement vectors from base dataset...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 97.03it/s]
    Dataset has been saved in measurements/CBSD500/deblurring




.. GENERATED FROM PYTHON SOURCE LINES 108-114

Define the  DEQ algorithm.
----------------------------------------------------------------------------------------
We use the helper function :meth:`deepinv.unfolded.DEQ_builder` to defined the DEQ architecture.
The chosen algorithm is here HQS (Half Quadratic Splitting).
Note for DEQ, the prior and regularization parameters should be common for all iterations
to keep a constant fixed-point operator.

.. GENERATED FROM PYTHON SOURCE LINES 114-165

.. code-block:: default



    # Select the data fidelity term
    data_fidelity = L2()

    # Set up the trainable denoising prior
    denoiser = DnCNN(
        in_channels=3, out_channels=3, depth=7, device=device, pretrained=None, train=True
    )

    # Here the prior model is common for all iterations
    prior = PnP(denoiser=denoiser)

    # Unrolled optimization algorithm parameters
    max_iter = 20 if torch.cuda.is_available() else 10
    lamb = 1.0  # Initial value for the regularization parameter.
    stepsize = 1.0  # Initial value for the stepsize. A single stepsize is common for each iterations.
    sigma_denoiser = 0.03  # Initial value for the denoiser parameter. A single value is common for each iterations.
    anderson_acceleration_forward = True  # use Anderson acceleration for the forward pass.
    anderson_acceleration_backward = (
        True  # use Anderson acceleration for the backward pass.
    )
    anderson_history_size = (
        5 if torch.cuda.is_available() else 3
    )  # history size for Anderson acceleration.

    params_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary
        "stepsize": stepsize,
        "g_param": sigma_denoiser,
        "lambda": lamb,
    }
    trainable_params = [
        "lambda",
        "stepsize",
        "g_param",
    ]  # define which parameters from 'params_algo' are trainable

    # Define the unfolded trainable model.
    model = DEQ_builder(
        iteration="HQS",  # For now DEQ is only possible with PGD, HQS and GD optimization algorithms.
        params_algo=params_algo.copy(),
        trainable_params=trainable_params,
        data_fidelity=data_fidelity,
        max_iter=max_iter,
        prior=prior,
        anderson_acceleration=anderson_acceleration_forward,
        anderson_acceleration_backward=anderson_acceleration_backward,
        history_size_backward=anderson_history_size,
        history_size=anderson_history_size,
    )








.. GENERATED FROM PYTHON SOURCE LINES 166-169

Define the training parameters.
-------------------------------
We use the Adam optimizer and the StepLR scheduler.

.. GENERATED FROM PYTHON SOURCE LINES 169-195

.. code-block:: default



    # training parameters
    epochs = 10
    learning_rate = 5e-4
    train_batch_size = 32 if torch.cuda.is_available() else 1
    test_batch_size = 3

    # choose optimizer and scheduler
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))

    # choose supervised training loss
    losses = [dinv.loss.SupLoss(metric=dinv.metric.mse())]

    # Logging parameters
    verbose = True
    wandb_vis = False  # plot curves and images in Weight&Bias

    train_dataloader = DataLoader(
        train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True
    )
    test_dataloader = DataLoader(
        test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False
    )








.. GENERATED FROM PYTHON SOURCE LINES 196-199

Train the network
-----------------
We train the network using the library's train function.

.. GENERATED FROM PYTHON SOURCE LINES 199-215

.. code-block:: default


    train(
        model=model,
        train_dataloader=train_dataloader,
        eval_dataloader=test_dataloader,
        epochs=epochs,
        scheduler=scheduler,
        losses=losses,
        physics=physics,
        optimizer=optimizer,
        device=device,
        save_path=str(CKPT_DIR / operation),
        verbose=verbose,
        wandb_vis=wandb_vis,  # training visualization can be done in Weight&Bias
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 188166 trainable parameters
            23-10-24-10:27:04       [ 1/10] loss=9.51e-03   Loss_sup=9.51e-03       Train_psnr_model=20.78  Eval_psnr_model=22.72   
            23-10-24-10:27:07       [ 2/10] loss=6.76e-03   Loss_sup=6.76e-03       Train_psnr_model=22.11  Eval_psnr_model=22.98   
            23-10-24-10:27:09       [ 3/10] loss=6.36e-03   Loss_sup=6.36e-03       Train_psnr_model=22.51  Eval_psnr_model=23.37   
            23-10-24-10:27:11       [ 4/10] loss=5.61e-03   Loss_sup=5.61e-03       Train_psnr_model=23.27  Eval_psnr_model=24.15   
            23-10-24-10:27:14       [ 5/10] loss=4.93e-03   Loss_sup=4.93e-03       Train_psnr_model=24.07  Eval_psnr_model=24.82   
            23-10-24-10:27:16       [ 6/10] loss=4.36e-03   Loss_sup=4.36e-03       Train_psnr_model=24.93  Eval_psnr_model=25.14   
            23-10-24-10:27:18       [ 7/10] loss=4.07e-03   Loss_sup=4.07e-03       Train_psnr_model=25.43  Eval_psnr_model=25.64   
            23-10-24-10:27:20       [ 8/10] loss=3.89e-03   Loss_sup=3.89e-03       Train_psnr_model=25.85  Eval_psnr_model=25.51   
            23-10-24-10:27:23       [ 9/10] loss=3.71e-03   Loss_sup=3.71e-03       Train_psnr_model=26.05  Eval_psnr_model=25.71   
            23-10-24-10:27:25       [10/10] loss=3.64e-03   Loss_sup=3.64e-03       Train_psnr_model=26.24  Eval_psnr_model=25.78   

    BaseDEQ(
      (fixed_point): FixedPoint(
        (iterator): HQSIteration(
          (f_step): fStepHQS()
          (g_step): gStepHQS()
        )
      )
      (init_params_algo): ParameterDict(
          (beta): Object of type: list
          (g_param): Object of type: ParameterList
          (lambda): Object of type: ParameterList
          (stepsize): Object of type: ParameterList
        (g_param): ParameterList(  (0): Parameter containing: [torch.float32 of size ])
        (lambda): ParameterList(  (0): Parameter containing: [torch.float32 of size ])
        (stepsize): ParameterList(  (0): Parameter containing: [torch.float32 of size ])
      )
      (params_algo): ParameterDict(
          (beta): Object of type: list
          (g_param): Object of type: ParameterList
          (lambda): Object of type: ParameterList
          (stepsize): Object of type: ParameterList
        (g_param): ParameterList(  (0): Parameter containing: [torch.float32 of size ])
        (lambda): ParameterList(  (0): Parameter containing: [torch.float32 of size ])
        (stepsize): ParameterList(  (0): Parameter containing: [torch.float32 of size ])
      )
      (prior): ModuleList(
        (0): PnP(
          (denoiser): DnCNN(
            (in_conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (conv_list): ModuleList(
              (0-4): 5 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (out_conv): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nl_list): ModuleList(
              (0-5): 6 x ReLU()
            )
          )
        )
      )
      (data_fidelity): ModuleList(
        (0): L2()
      )
    )



.. GENERATED FROM PYTHON SOURCE LINES 216-220

Test the network
--------------------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 220-237

.. code-block:: default


    method = "DEQ_HQS"
    save_folder = RESULTS_DIR / method / operation
    wandb_vis = False  # plot curves and images in Weight&Bias.
    plot_images = True  # plot images. Images are saved in save_folder.

    test(
        model=model,
        test_dataloader=test_dataloader,
        physics=physics,
        device=device,
        plot_metrics=True,
        plot_images=plot_images,
        save_folder=save_folder,
        verbose=verbose,
        wandb_vis=wandb_vis,
    )



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/unfolded/images/sphx_glr_demo_DEQ_001.png
         :alt: Input, Linear, Recons., GT
         :srcset: /auto_examples/unfolded/images/sphx_glr_demo_DEQ_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/unfolded/images/sphx_glr_demo_DEQ_002.png
         :alt: $PSNR(x_k)$, Residual $\frac{||x_{k+1} - x_k||}{||x_k||}$
         :srcset: /auto_examples/unfolded/images/sphx_glr_demo_DEQ_002.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Processing data of operator 1 out of 1
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:04<00:00,  4.21s/it]    100%|██████████| 1/1 [00:04<00:00,  4.21s/it]
    Test PSNR: Linear rec.: 21.12+-0.00 dB | Model: 25.78+-0.00 dB. 

    (25.77739715576172, 0.0, 21.124963760375977, 0.0)




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 27.673 seconds)


.. _sphx_glr_download_auto_examples_unfolded_demo_DEQ.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_DEQ.py <demo_DEQ.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_DEQ.ipynb <demo_DEQ.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_


.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/unfolded/demo_LISTA.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_unfolded_demo_LISTA.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_unfolded_demo_LISTA.py:


Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing
====================================================================================================

This example shows how to implement the `LISTA <http://yann.lecun.com/exdb/publis/pdf/gregor-icml-10.pdf>`_ algorithm
for a compressed sensing problem. In a nutshell, LISTA is an unfolded proximal gradient algorithm involving a
soft-thresholding proximal operator with learnable thresholding parameters.

.. GENERATED FROM PYTHON SOURCE LINES 10-24

.. code-block:: default

    from pathlib import Path
    import torch
    from torchvision import datasets
    from torchvision import transforms

    import deepinv as dinv
    from torch.utils.data import DataLoader
    from deepinv.optim.data_fidelity import L2
    from deepinv.optim.prior import PnP
    from deepinv.unfolded import unfolded_builder
    from deepinv.training_utils import train, test

    import matplotlib.pyplot as plt








.. GENERATED FROM PYTHON SOURCE LINES 25-28

Setup paths for data loading and results.
-----------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 28-40

.. code-block:: default


    BASE_DIR = Path(".")
    ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
    DATA_DIR = BASE_DIR / "measurements"
    RESULTS_DIR = BASE_DIR / "results"
    CKPT_DIR = BASE_DIR / "ckpts"

    # Set the global random seed from pytorch to ensure reproducibility of the example.
    torch.manual_seed(0)

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"








.. GENERATED FROM PYTHON SOURCE LINES 41-44

Load base image datasets and degradation operators.
----------------------------------------------------------------------------------------
In this example, we use MNIST as the base dataset.

.. GENERATED FROM PYTHON SOURCE LINES 44-60

.. code-block:: default


    img_size = 28
    n_channels = 1
    operation = "compressed-sensing"
    train_dataset_name = "MNIST_train"

    # Generate training and evaluation datasets in HDF5 folders and load them.
    train_test_transform = transforms.Compose([transforms.ToTensor()])
    train_base_dataset = datasets.MNIST(
        root=ORIGINAL_DATA_DIR, train=True, transform=train_test_transform, download=True
    )
    test_base_dataset = datasets.MNIST(
        root=ORIGINAL_DATA_DIR, train=False, transform=train_test_transform, download=True
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to datasets/MNIST/raw/train-images-idx3-ubyte.gz
      0%|          | 0/9912422 [00:00<?, ?it/s]    100%|██████████| 9912422/9912422 [00:00<00:00, 143261768.26it/s]
    Extracting datasets/MNIST/raw/train-images-idx3-ubyte.gz to datasets/MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to datasets/MNIST/raw/train-labels-idx1-ubyte.gz
      0%|          | 0/28881 [00:00<?, ?it/s]    100%|██████████| 28881/28881 [00:00<00:00, 160232399.24it/s]
    Extracting datasets/MNIST/raw/train-labels-idx1-ubyte.gz to datasets/MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to datasets/MNIST/raw/t10k-images-idx3-ubyte.gz
      0%|          | 0/1648877 [00:00<?, ?it/s]     12%|█▏        | 196608/1648877 [00:00<00:00, 1510852.23it/s]     22%|██▏       | 360448/1648877 [00:00<00:01, 1176380.53it/s]     30%|██▉       | 491520/1648877 [00:00<00:01, 1082003.54it/s]     38%|███▊      | 622592/1648877 [00:00<00:00, 1044213.38it/s]     46%|████▌     | 753664/1648877 [00:00<00:00, 1035121.27it/s]     54%|█████▎    | 884736/1648877 [00:00<00:00, 1025685.40it/s]     62%|██████▏   | 1015808/1648877 [00:00<00:00, 1083489.72it/s]     97%|█████████▋| 1605632/1648877 [00:01<00:00, 2377751.02it/s]    100%|██████████| 1648877/1648877 [00:01<00:00, 1590042.12it/s]
    Extracting datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to datasets/MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz
      0%|          | 0/4542 [00:00<?, ?it/s]    100%|██████████| 4542/4542 [00:00<00:00, 32676721.73it/s]
    Extracting datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to datasets/MNIST/raw





.. GENERATED FROM PYTHON SOURCE LINES 61-68

Generate a dataset of compressed measurements and load it.
----------------------------------------------------------------------------
We use the compressed sensing class from the physics module to generate a dataset of highly-compressed measurements
(10% of the total number of pixels).

The forward operator is defined as :math:`y = Ax`
where :math:`A` is a (normalized) random Gaussian matrix.

.. GENERATED FROM PYTHON SOURCE LINES 68-98

.. code-block:: default



    # Use parallel dataloader if using a GPU to fasten training, otherwise, as all computes are on CPU, use synchronous
    # data loading.
    num_workers = 4 if torch.cuda.is_available() else 0

    # Generate the compressed sensing measurement operator with 10x under-sampling factor.
    physics = dinv.physics.CompressedSensing(
        m=78, img_shape=(n_channels, img_size, img_size), fast=True, device=device
    )
    my_dataset_name = "demo_LISTA"
    n_images_max = (
        1000 if torch.cuda.is_available() else 200
    )  # maximal number of images used for training
    measurement_dir = DATA_DIR / train_dataset_name / operation
    generated_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_base_dataset,
        test_dataset=test_base_dataset,
        physics=physics,
        device=device,
        save_dir=measurement_dir,
        train_datapoints=n_images_max,
        test_datapoints=8,
        num_workers=num_workers,
        dataset_filename=str(my_dataset_name),
    )

    train_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)
    test_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Computing train measurement vectors from base dataset...
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:00<00:00, 11.64it/s]
    Computing test measurement vectors from base dataset...
      0%|          | 0/2 [00:00<?, ?it/s]    100%|██████████| 2/2 [00:00<00:00, 527.82it/s]
    Dataset has been saved in measurements/MNIST_train/compressed-sensing




.. GENERATED FROM PYTHON SOURCE LINES 99-122

Define the unfolded Proximal Gradient algorithm.
------------------------------------------------------------------------
In this example, following the original `LISTA algorithm <http://yann.lecun.com/exdb/publis/pdf/gregor-icml-10.pdf>`_,
the backbone algorithm we unfold is the proximal gradient algorithm which minimizes the following objective function

.. math::

         \min_x \frac{\lambda}{2} \|y - Ax\|_2^2 + \|Wx\|_1

where :math:`\lambda` is the regularization parameter.
The proximal gradient iteration (see also :class:`deepinv.optim.optim_iterators.PGDIteration`) is defined as

  .. math::
          x_{k+1} = \text{prox}_{\gamma g}(x_k - \gamma \lambda A^T (Ax_k - y))

where :math:`\gamma` is the stepsize and :math:`\text{prox}_{g}` is the proximity operator of :math:`g(x) = \|Wx\|_1`
which corresponds to soft-thresholding with a wavelet basis (see :class:`deepinv.models.WaveletDict`).

We use :meth:`deepinv.unfolded.unfolded_builder` to define the unfolded algorithm
and set both the stepsizes of the LISTA algorithm :math:`\gamma` (``stepsize``) and the soft
thresholding parameters :math:`\lambda` (``1/g_param``) as learnable parameters.
These parameters are initialized with a table of length max_iter,
yielding a distinct ``stepsize`` and ``g_param`` value for each iteration of the algorithm.

.. GENERATED FROM PYTHON SOURCE LINES 122-172

.. code-block:: default


    # Select the data fidelity term
    data_fidelity = L2()

    # Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.
    # If the prior is initialized with a list of length max_iter,
    # then a distinct weight is trained for each PGD iteration.
    # For fixed trained model prior across iterations, initialize with a single model.
    max_iter = 30 if torch.cuda.is_available() else 10  # Number of unrolled iterations
    level = 2
    prior = [
        PnP(denoiser=dinv.models.WaveletPrior(wv="db8", level=level, device=device))
        for i in range(max_iter)
    ]

    # Unrolled optimization algorithm parameters

    lamb = [1.0] * max_iter  # initialization of the regularization parameter.
    # A distinct lamb is trained for each iteration.

    stepsize = [1.0] * max_iter  # initialization of the stepsizes.
    # A distinct stepsize is trained for each iteration.

    sigma_denoiser_init = 0.01
    sigma_denoiser = [sigma_denoiser_init * torch.ones(level, 3)] * max_iter
    # A distinct sigma_denoiser is trained for each iteration.

    params_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary
        "stepsize": stepsize,
        "g_param": sigma_denoiser,
        "lambda": lamb,
    }

    trainable_params = [
        "g_param",
        "stepsize",
        "lambda",
    ]  # define which parameters from 'params_algo' are trainable

    # Define the unfolded trainable model.
    model = unfolded_builder(
        iteration="PGD",
        params_algo=params_algo.copy(),
        trainable_params=trainable_params,
        data_fidelity=data_fidelity,
        max_iter=max_iter,
        prior=prior,
    ).to(device)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/deepinv/deepinv/deepinv/unfolded/unfolded.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
      [nn.Parameter(torch.tensor(el).to(device)) for el in param_value]




.. GENERATED FROM PYTHON SOURCE LINES 173-179

Define the training parameters.
-------------------------------

We now define training-related parameters,
number of epochs, optimizer (Adam) and its hyperparameters, and the train and test batch sizes.


.. GENERATED FROM PYTHON SOURCE LINES 179-206

.. code-block:: default



    # Training parameters
    epochs = 20 if torch.cuda.is_available() else 5
    learning_rate = 1e-3

    # Choose optimizer and scheduler
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0)

    # Choose supervised training loss
    losses = [dinv.loss.SupLoss(metric=dinv.metric.mse())]

    # Logging parameters
    verbose = True
    wandb_vis = False  # plot curves and images in Weight&Bias

    # Batch sizes and data loaders
    train_batch_size = 64 if torch.cuda.is_available() else 1
    test_batch_size = 64 if torch.cuda.is_available() else 8

    train_dataloader = DataLoader(
        train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True
    )
    test_dataloader = DataLoader(
        test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False
    )








.. GENERATED FROM PYTHON SOURCE LINES 207-212

Train the network.
-------------------------------------------

We train the network using the library's train function.


.. GENERATED FROM PYTHON SOURCE LINES 212-227

.. code-block:: default


    train(
        model=model,
        train_dataloader=train_dataloader,
        eval_dataloader=test_dataloader,
        epochs=epochs,
        losses=losses,
        physics=physics,
        optimizer=optimizer,
        device=device,
        save_path=str(CKPT_DIR / operation),
        verbose=verbose,
        wandb_vis=wandb_vis,  # training visualization can be done in Weight&Bias
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 80 trainable parameters
            23-10-24-10:24:10       [1/5]   loss=6.00e-02   Loss_sup=6.00e-02       Train_psnr_model=12.54  Eval_psnr_model=14.32   
            23-10-24-10:24:21       [2/5]   loss=4.69e-02   Loss_sup=4.69e-02       Train_psnr_model=13.52  Eval_psnr_model=14.64   
            23-10-24-10:24:31       [3/5]   loss=4.36e-02   Loss_sup=4.36e-02       Train_psnr_model=13.80  Eval_psnr_model=14.78   
            23-10-24-10:24:41       [4/5]   loss=4.22e-02   Loss_sup=4.22e-02       Train_psnr_model=13.94  Eval_psnr_model=14.83   
            23-10-24-10:24:52       [5/5]   loss=4.14e-02   Loss_sup=4.14e-02       Train_psnr_model=14.01  Eval_psnr_model=14.87   

    BaseUnfold(
      (fixed_point): FixedPoint(
        (iterator): PGDIteration(
          (f_step): fStepPGD()
          (g_step): gStepPGD()
        )
      )
      (init_params_algo): ParameterDict(
          (beta): Object of type: list
          (g_param): Object of type: ParameterList
          (lambda): Object of type: ParameterList
          (stepsize): Object of type: ParameterList
        (g_param): ParameterList(
            (0): Parameter containing: [torch.float32 of size 2x3]
            (1): Parameter containing: [torch.float32 of size 2x3]
            (2): Parameter containing: [torch.float32 of size 2x3]
            (3): Parameter containing: [torch.float32 of size 2x3]
            (4): Parameter containing: [torch.float32 of size 2x3]
            (5): Parameter containing: [torch.float32 of size 2x3]
            (6): Parameter containing: [torch.float32 of size 2x3]
            (7): Parameter containing: [torch.float32 of size 2x3]
            (8): Parameter containing: [torch.float32 of size 2x3]
            (9): Parameter containing: [torch.float32 of size 2x3]
        )
        (lambda): ParameterList(
            (0): Parameter containing: [torch.float32 of size ]
            (1): Parameter containing: [torch.float32 of size ]
            (2): Parameter containing: [torch.float32 of size ]
            (3): Parameter containing: [torch.float32 of size ]
            (4): Parameter containing: [torch.float32 of size ]
            (5): Parameter containing: [torch.float32 of size ]
            (6): Parameter containing: [torch.float32 of size ]
            (7): Parameter containing: [torch.float32 of size ]
            (8): Parameter containing: [torch.float32 of size ]
            (9): Parameter containing: [torch.float32 of size ]
        )
        (stepsize): ParameterList(
            (0): Parameter containing: [torch.float32 of size ]
            (1): Parameter containing: [torch.float32 of size ]
            (2): Parameter containing: [torch.float32 of size ]
            (3): Parameter containing: [torch.float32 of size ]
            (4): Parameter containing: [torch.float32 of size ]
            (5): Parameter containing: [torch.float32 of size ]
            (6): Parameter containing: [torch.float32 of size ]
            (7): Parameter containing: [torch.float32 of size ]
            (8): Parameter containing: [torch.float32 of size ]
            (9): Parameter containing: [torch.float32 of size ]
        )
      )
      (params_algo): ParameterDict(
          (beta): Object of type: list
          (g_param): Object of type: ParameterList
          (lambda): Object of type: ParameterList
          (stepsize): Object of type: ParameterList
        (g_param): ParameterList(
            (0): Parameter containing: [torch.float32 of size 2x3]
            (1): Parameter containing: [torch.float32 of size 2x3]
            (2): Parameter containing: [torch.float32 of size 2x3]
            (3): Parameter containing: [torch.float32 of size 2x3]
            (4): Parameter containing: [torch.float32 of size 2x3]
            (5): Parameter containing: [torch.float32 of size 2x3]
            (6): Parameter containing: [torch.float32 of size 2x3]
            (7): Parameter containing: [torch.float32 of size 2x3]
            (8): Parameter containing: [torch.float32 of size 2x3]
            (9): Parameter containing: [torch.float32 of size 2x3]
        )
        (lambda): ParameterList(
            (0): Parameter containing: [torch.float32 of size ]
            (1): Parameter containing: [torch.float32 of size ]
            (2): Parameter containing: [torch.float32 of size ]
            (3): Parameter containing: [torch.float32 of size ]
            (4): Parameter containing: [torch.float32 of size ]
            (5): Parameter containing: [torch.float32 of size ]
            (6): Parameter containing: [torch.float32 of size ]
            (7): Parameter containing: [torch.float32 of size ]
            (8): Parameter containing: [torch.float32 of size ]
            (9): Parameter containing: [torch.float32 of size ]
        )
        (stepsize): ParameterList(
            (0): Parameter containing: [torch.float32 of size ]
            (1): Parameter containing: [torch.float32 of size ]
            (2): Parameter containing: [torch.float32 of size ]
            (3): Parameter containing: [torch.float32 of size ]
            (4): Parameter containing: [torch.float32 of size ]
            (5): Parameter containing: [torch.float32 of size ]
            (6): Parameter containing: [torch.float32 of size ]
            (7): Parameter containing: [torch.float32 of size ]
            (8): Parameter containing: [torch.float32 of size ]
            (9): Parameter containing: [torch.float32 of size ]
        )
      )
      (prior): ModuleList(
        (0-9): 10 x PnP(
          (denoiser): WaveletPrior(
            (dwt): DWTForward()
            (iwt): DWTInverse()
          )
        )
      )
      (data_fidelity): ModuleList(
        (0): L2()
      )
    )



.. GENERATED FROM PYTHON SOURCE LINES 228-235

Test the network.
---------------------------

We now test the learned unrolled network on the test dataset. In the plotted results, the `Linear` column shows the
measurements back-projected in the image domain, the `Recons` column shows the output of our LISTA network,
and `GT` shows the ground truth.


.. GENERATED FROM PYTHON SOURCE LINES 235-251

.. code-block:: default


    plot_images = True
    method = "unfolded_pgd"

    test(
        model=model,
        test_dataloader=test_dataloader,
        physics=physics,
        device=device,
        plot_images=plot_images,
        save_folder=RESULTS_DIR / method / operation,
        verbose=verbose,
        wandb_vis=wandb_vis,
    )





.. image-sg:: /auto_examples/unfolded/images/sphx_glr_demo_LISTA_001.png
   :alt: Linear, Recons., GT
   :srcset: /auto_examples/unfolded/images/sphx_glr_demo_LISTA_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Processing data of operator 1 out of 1
      0%|          | 0/1 [00:00<?, ?it/s]    100%|██████████| 1/1 [00:03<00:00,  3.86s/it]    100%|██████████| 1/1 [00:03<00:00,  3.86s/it]
    Test PSNR: Linear rec.: 11.42+-0.00 dB | Model: 14.87+-0.00 dB. 

    (14.869588851928711, 0.0, 11.419172286987305, 0.0)



.. GENERATED FROM PYTHON SOURCE LINES 252-254

Plotting the learned parameters.
------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 254-257

.. code-block:: default

    dinv.utils.plotting.plot_parameters(
        model, init_params=params_algo, save_dir=RESULTS_DIR / method / operation
    )



.. image-sg:: /auto_examples/unfolded/images/sphx_glr_demo_LISTA_002.png
   :alt: demo LISTA
   :srcset: /auto_examples/unfolded/images/sphx_glr_demo_LISTA_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 57.739 seconds)


.. _sphx_glr_download_auto_examples_unfolded_demo_LISTA.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_LISTA.py <demo_LISTA.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_LISTA.ipynb <demo_LISTA.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
